# C++知识汇总

## static 关键字

### 静态成员变量

- 类的==所有对象共有==，无论定义了多少个对象，静态成员变量都只有一份。

- 静态成员变量在==全局数据区==分配内存，==不占用对象的内存==，==在没有产生类对象时其作用域就可见==。

- 静态成员变量的内存空间是在==初始化时分配==的，它==必须初始化==，而且==只能在类体外进行==。否则，编译能通过，链接不能通过。静态数据区的变量都有默认的初始值，而动态数据区的变量默认是垃圾值。

- 静态成员变量和普通静态变量一样，==编译时在静态数据区分配内存，到程序结束时才释放==。静态数据成员一样遵从`public`等访问规则。

- 和全局变量相比，优势在于：1. 静态成员变量==没有进入全局命名空间==，因此不存在与程序中其它全局命名冲突的可能。2. 可以实现信息隐藏，静态成员变量可以是`private`成员，而全局变量不能。

### 静态成员函数

- 静态成员函数与静态成员变量一样，都是类的内部实现，属于类定义的一部分，并不具体作用于某个对象。因此==静态成员函数不具有this指针，无法访问属于类对象的非静态成员变量和非静态成员函数==。同时没有`this`指针的额外开销，速度上稍快。

- 在使用包含静态成员的类时，有时候会调用拷贝构造函数生成临时的隐藏的类对象，这个临时对象在消亡时会调用析构函数，此时有可能对静态变量做操作（例如`total--`）。可是这个对象生成时没有执行构造函数中的`total++`操作。

### 静态全局变量

- 静态全局变量在==全局数据区==分配内存。

- 未经初始化的静态全局变量会被程序自动初始化为0。

- 静态全局变量在声明它的整个文件中都是可见的，而在==文件之外是不可见==的。

### 静态局部变量

- 静态局部变量在==全局数据区==分配内存。

- 静态局部变量在程序==执行到该对象的声明处时被首次初始化，以后的函数调用不再进行初始化==。静态局部变量一般在声明处初始化，如果没有显式初始化，会被程序自动初始化为0。

- 静态局部变量始终驻留在全局数据区，直到程序运行结束。但其==作用域为局部作用域==，当定义它的函数或语句块结束时，其作用域随之结束。

### 静态函数

- 静态函数==只在当前文件中可见==，不能被其它文件使用。

- 其它文件中可以定义相同名字的函数，不会发生冲突。

## C++11 的三种智能指针

### shared_ptr

允许多个指针指向相同的对象，内部使用引用计数实现。每一个`shared_ptr`的拷贝都指向相同的内存，每增加一个内部的引用就加1，每析构一个内部的引用就减1。内部引用减为0的时候，就会自动删除所指向的堆内存。`shared_ptr`内部的引用计数是线程安全的，但是对象的读取需要加锁。

注意不能将指针直接赋值给一个智能指针，因为智能指针是一个类。可以传入指针通过构造函数初始化，也可以使用`make_shared`函数初始化。

```c++
#include <iostream>
#include <memory>
using namespace std;

int main() {
    {
        int a = 10;
        shared_ptr<int> ptra = make_shared<int>(a);
        shared_ptr<int> ptra2(ptra);
        cout << ptra.use_count() << endl; // 2

        int b = 20;
        int *pb = &a;
        // shared_ptr<int> ptrb = pb;  // 错误 不能把指针赋值给类
        shared_ptr<int> ptrb = make_shared<int>(b);
        ptra2 = ptrb;
        pb = ptrb.get(); // 获取原始指针

        cout << ptra.use_count() << endl; // 1
        cout << ptrb.use_count() << endl; // 2
    }
}
```

### weak_ptr

`weak_ptr`是为了配合`shared_ptr`而引入的一种智能指针，它不具有普通指针的行为，没有重载operator*和->，它的最大作用在于协助`shared_ptr`工作，像旁观者那样观测资源的使用情况。

`weak_ptr`可以从一个`shared_ptr`或者另一个`weak_ptr`对象构造，获得资源的观测权。但`weak_ptr`没有共享资源，它的构造不会引起指针引用计数的增加。使用`weak_ptr`的成员函数`use_count()`可以观测资源的引用计数，另一个成员函数`expired()`的功能等价于`use_count()==0`，但更快，表示被观测的资源（也就是shared_ptr的管理的资源）已经不复存在。

`weak_ptr`可以使用一个非常重要的成员函数`lock()`从被观测的`shared_ptr`获得一个可用的`shared_ptr`对象， 从而操作资源。但当`expired()==true`的时候，`lock()`函数将返回一个存储空指针的`shared_ptr`。

```c++
#include <iostream>
#include <memory>
using namespace std;

int main() {
    {
        shared_ptr<int> sh_ptr = make_shared<int>(10);
        cout << sh_ptr.use_count() << endl; // 1

        weak_ptr<int> wp(sh_ptr);
        cout << wp.use_count() << endl; // 1

        if(!wp.expired()) {
            shared_ptr<int> sh_ptr2 = wp.lock();
            *sh_ptr = 100;
            cout << wp.use_count() << endl; // 2
        }
    }
}
```

### unique_ptr

`unique_ptr`唯一拥有其所指对象，同一时刻只能有一个`unique_ptr`指向给定对象（通过禁止拷贝语义、只有移动语义来实现）。相比于原始指针，`unique_ptr`用于其RAII的特性，使得在出现异常的情况下，动态资源能得到释放。

`unique_ptr`指针本身的生命周期：从`unique_ptr`指针创建时开始，直到离开作用域。离开作用域时，若其指向对象，则将其所指对象销毁（默认使用delete操作符，用户可指定其他操作）。

`unique_ptr`指针与其所指对象的关系：在智能指针生命周期内，可以改变智能指针所指对象，如创建智能指针时通过构造函数指定、通过`reset`方法重新指定、通过`release()`方法释放所有权、通过移动语义转移所有权。

注意，不能忽视 `release()` 返回的结果，其返回的指针通常用来初始化或赋值另一个智能指针，如果我们只调用 `release()` 而没有删除其返回值，会造成内存泄露。

```c++
#include <iostream>
#include <memory>
using namespace std;

int main() {
    {
        unique_ptr<int> uptr(new int(10));  // 绑定动态对象
        // unique_ptr<int> uptr2 = uptr;  // 不能赋值
        // unique_ptr<int> uptr2(uptr);  // 不能拷贝
        unique_ptr<int> uptr2 = move(uptr); // 转移所有权
        auto p = uptr2.release(); // 释放所有权
        delete p;
    }
    // 超过uptr的作用域，内存释放
}
```

### 智能指针的设计和实现

下面是一个简单智能指针的demo。智能指针类将一个计数器与类指向的对象相关联，引用计数跟踪该类有多少个对象共享同一指针。每次创建类的新对象时，初始化指针并将引用计数置为1；当对象作为另一对象的副本而创建时，拷贝构造函数拷贝指针并增加与之相应的引用计数；对一个对象进行赋值时，赋值操作符减少左操作数所指对象的引用计数（如果引用计数为减至0，则删除对象），并增加右操作数所指对象的引用计数；调用析构函数时，构造函数减少引用计数（如果引用计数减至0，则删除基础对象）。智能指针还有许多其他功能，比较有用的是自动销毁。这主要是==利用栈对象的有限作用域以及临时对象（有限作用域实现）析构函数释放内存==。

```c++
#include <iostream>
#include <memory>
using namespace std;

template<typename T>
class SmartPointer {
private:
    T* _ptr;
    size_t* _count;
public:
    SmartPointer(T* ptr = nullptr): _ptr(ptr) {
        if (_ptr) {
            _count = new size_t(1);
        } else {
            _count = new size_t(0);
        }
    }

    SmartPointer(const SmartPointer& ptr) {
        if (this != &ptr) {
            this->_ptr = ptr._ptr;
            this->_count = ptr._count;
            (*this->_count)++;
        }
    }

    SmartPointer& operator=(const SmartPointer& ptr) {
        if (this->_ptr == ptr._ptr) {
            return *this;
        }

        if (this->_ptr) {
            (*this->_count)--;
            if (this->_count == 0) {
                delete this->_ptr;
                delete this->_count;
            }
        }

        this->_ptr = ptr._ptr;
        this->_count = ptr._count;
        (*this->_count)++;
        return *this;
    }

    T& operator*() {
        assert(this->_ptr == nullptr);
        return *(this->_ptr);

    }

    T* operator->() {
        assert(this->_ptr == nullptr);
        return this->_ptr;
    }

    ~SmartPointer() {
        (*this->_count)--;
        if (*this->_count == 0) {
            delete this->_ptr;
            delete this->_count;
        }
    }

    size_t use_count(){
        return *this->_count;
    }
};

int main() {
    {
        SmartPointer<int> sp(new int(10));
        SmartPointer<int> sp2(sp);
        SmartPointer<int> sp3(new int(20));
        sp2 = sp3;
        cout << sp.use_count() << endl;
        cout << sp3.use_count() << endl;
    }
    // delete operator
}
```

## 四种强制类型转换

### static_cast

- 类之间转换的时候，==上行转换（派生类指针或引用转换为基类表示）是安全的，下行转换（基类指针或引用转换为派生类表示）由于没有动态类型检查，所以是不安全的==。

- 用于基本数据类型之间的转换。

- 把空指针转换成目标类型的空指针。

- 把任何类型的表达式转换成void类型。注意，不能转换掉表达式的const、volitale或者__unaligned属性。

  ```c++
  int a = 10;
  int b = 3;
  double res = static_cast<double>(a) / static_cast<double>(b);
  ```

### const_cast

- 用于强制去除指向常数对象的指针或引用的常量性，==其去除常量性的对象必须是指针或引用==。

- 常量指针被转化为非常量指针，并且仍然指向原来的对象。

- 常量引用被转换成非常量引用，并且仍然指向原来的对象；常量对象被转换成非常量对象。

  ```c++
  const int a = 10;
  const int *p = &a;
  // *p = 20; // *p具有常量性不可修改
  // int b = const_cast<int>(a); // 强制转换对象必须为指针或引用
  int *q;
  q = const_cast<int *>(p);
  *q = 20;
  cout << a << " " << *p << " " << *q << endl; // 10 20 20
  cout << &a << " " << p << " " << q << endl; // 002CFAF4 002CFAF4 002CFAF4
  ```

  我们称`*q=20`语句为未定义行为语句，所谓的未定义行为是指在标准的C++规范中并没有明确规定这种语句的具体行为，该语句的具体行为由编译器来自行决定如何处理。

### reinterpret_cast

- 改变指针或引用的类型。

- 将指针或引用转换为一个足够长度的整形。

- 将整形转换为指针或引用类型。

  ```c++
  int *a = new int;
  double *d = reinterpret_cast<double *>(a);
  ```

  在使用`reinterpret_cast`强制转换过程==仅仅只是比特位的拷贝==。

### dynamic_cast

- 其他三种都是编译时完成的，`dynamic_cast`是运行时处理的，运行时要进行类型检查。

- 不能用于内置的基本数据类型的强制转换。

- `dynamic_cast`转换如果成功的话返回的是指向类的指针或引用，转换失败的话则会返回NULL。

- 使用`dynamic_cast`进行转换的，==基类中一定要有虚函数==，否则编译不通过。

  这是由于运行时类型检查需要运行时类型信息，而这个信息存储在类的虚函数表中，只有定义了虚函数的类才有虚函数表。

- 在类的转换时，在类层次间进行上行转换时，`dynamic_cast`和`static_cast`的效果是一样的。在进行下行转换时，`dynamic_cast`具有类型检查的功能，比`static_cast`更安全。==向下转换的成功与否还与将要转换的类型有关，即要转换的指针指向的对象的实际类型与转换以后的对象类型一定要相同，否则转换失败==。

  ```c++
  #include<iostream>
  using namespace std;
  
  class base
  {
  public:
      virtual void f() {
          cout << "base f()" << endl;
      }
  };
  
  class derived: public base
  {
  public:
      void f() {
          cout << "derived f()" << endl;
      }
  };
  
  int main()
  {
      base *a1 = new base;
      base *a2 = new derived;
      derived *p;
      // p = new base; // 编译错误
      p = dynamic_cast<derived *>(a1); // 结果为nullptr
      p = dynamic_cast<derived *>(a2); // 结果为not nullptr
      return 0;
  }
  ```

## C++ 内存管理和内存分配

### Windows 内存管理机制

![img](https://pic2.zhimg.com/80/v2-26bdd3d3bcb29400bf29ff98d322ec9d_1440w.jpg)

Windows将物理内存映射为连续的虚拟内存（通过TLB），并提供了一些与虚拟内存相关的API对虚拟内存进行管理，在Virtual Memory API之上又构建了Heap Memory API，而C的内存管理机制（malloc，free）就构建在Heap Memory API之上。==使用VirtualAlloc分配内存时，每次只能分配页面大小（默认4KB）整数倍的连续虚拟内存（但是两次连续调用所分配的内存不一定连续）。==

### Linux 内存管理机制

![img](https://pic2.zhimg.com/80/v2-4adcd35f4d5f0cfb1f938a1e3ecaa671_1440w.jpg)

Linux 中可以借助`brk`或`mmap`函数从用户空间中申请连续内存。通过调用`brk(0)`可以获取指向用户空间某一地址的指针，随后调用`brk(len)`可以在原指针地址的基础上移动该指针以达到申请或释放内存的目的。而`mmap`则是直接在用户空间中申请一块连续的空闲内存。

### C++ 内存管理机制

<img src="https://pic3.zhimg.com/80/v2-bf1db515c405109fb005270fe8e4591a_1440w.jpg" alt="img" style="zoom:50%;" />

从 Code Segment 到 Stack 的内存地址均位于用户空间中，其地址空间由低到高。其中：

- Code Segment（代码段或 Text Segment ）中存放着**程序的机器码和只读数据**，可执行指令就是从这里取得的。如果可能，系统会安排相同程序的多个运行实体共享这些实例代码。这个段在内存中一般被标记为只读，任何对该区的写操作都会导致段错误（Segmentation Fault）。
- Data Segment 中存放**已初始化的全局或静态变量**。
- BSS 中存放**未初始化的全局或静态变量**。
- Heap（堆），**堆的大小并不固定，可动态扩张或缩减**。其分配由`malloc()`、`new()`等这类实时内存分配函数来实现（`brk`函数也是从这里分配内存）。
- Stack（栈），用来存储**函数调用时的临时信息**，如函数调用所传递的参数、函数的返回地址、函数的局部变量等。 在程序运行时由编译器在需要的时候分配，在不需要的时候自动清除。栈内存的申请和释放遵循LIFO（先进后出）。

### 堆和栈的区别

1. **分配和管理方式不同**
   - 堆是动态分配的，其空间的分配和释放都由程序员控制。
   - 栈由编译器自动管理。栈有两种分配方式：静态分配和动态分配。
2. **产生碎片不同**
   - 对堆来说，频繁的`new`/`delete`或者`malloc`/`free`可能会造成内存空间的不连续，造成大量的碎片，使程序效率降低。
   - 对栈而言，则不存在碎片问题，因为栈是先进后出的队列，永远不可能有一个内存块从栈中间弹出。
3. **增长方向不同**
   - 堆由低地址向高地址增长。
   - 栈由高地址向低地址增长。

### 函数栈

可执行程序的文件包含 BSS，Data Segment 和 Code Segment，当可执行程序载入内存后，系统会保留一些空间，即堆区和栈区。堆区主要是动态分配的内存（默认情况下），而栈区主要是函数以及局部变量等（包括 main 函数）。一般而言，栈的空间小于堆的空间。

当调用函数时，一块连续内存（堆栈帧）压入栈；函数返回时，堆栈帧弹出。堆栈帧包含如下数据：

1. 函数返回地址
2. 局部变量 / CPU 寄存器数据备份

<img src="https://pic2.zhimg.com/80/v2-0d4da56aa33d089b5ee4cdd840153b99_1440w.jpg" alt="img" style="zoom: 67%;" />

假设对于下列代码：

```c++
void fun(int x, int y)
{
	int m, n;
    m = x;
    n = y;
}

int main()
{
    int a = 10;
    int b = 20;
    fun(a, b);
    return 0;
}
```

跳到 fun 函数后函数栈的情况如下图所示：

<img src="https://img-blog.csdnimg.cn/20190427181643120.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2x1Y2t5NTI1Mjk=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom:50%;" />

也就是对于每一个栈帧，其栈帧底部是局部变量，然后是一些寄存器的值，再是调用函数传入的实参。同时要保存返回地址和调用函数的 EBP（基址指针寄存器）。

### C++ new / delete 的原理与实现

C++中的`new`有三种形态：

1. `new operator`即我们经常使用的`T *ptr = new T()`。
2. `operator new`，类或结构体可以通过重载来决定如何为对象分配内存，与之对应的还有`operator delete`。`operator new`可以被`new operator`调用。

```c++
struct MyStruct
{
	void *operator new(size_t pSize)
	{
		std::cout << "operator new！" << std::endl;
		return malloc(pSize);
	}

	void operator delete(void *pPtr)
	{
		std::cout << "operator delete！" << std::endl;
		free(pPtr);
	}
};
```

3. `placement new`，可以实现在一块指定的内存上（这块内存可以由任意方式分配）构造对象（调用对象的构造函数）。如下所示：

```c++
void *memory = malloc(sizeof(Test));
Test *pt = new(memory) Test();
pt->~Test();
free(memory);
```

由`placement new`构造的对象在析构时，如果有析构函数则需要在释放时显式调用析构函数（不需要调用 delete 来释放内存）。它的意义在于我们可以利用 `placement new` 将内存**分配**和**构造**这两个模块分离（后续的 allocator 更好地践行了这一概念），这对于编写内存管理的代码非常重要，比如当我们想要编写内存池的代码时，可以预申请一块内存，然后通过 `placement new` 申请对象，一方面可以**避免频繁调用系统 new / delete 带来的开销**，另一方面可以自己控制内存的分配和释放。

### 为什么说 new 是低效的？

1. 一般来说，操作越简单，意味着封装了更多的实现细节。new 作为一个通用接口，需要处理任意时间、任意位置申请任意大小内存的请求，它在设计上就无法兼顾一些特殊场景的优化，在管理上也会带来一定开销。
2. 系统调用带来的开销。多数操作系统上，申请内存会从用户模式切换到内核模式，当前线程会 block 住，上下文切换将会消耗一定时间。
3. 分配可能是带锁的。这意味着分配难以并行化。

### 什么是内存泄露

**内存泄露是指由于疏忽或错误造成了程序未能释放掉不再使用的内存的情况。**

内存泄露的分类：

1. **堆内存泄露**：堆内存指的是程序运行中根据需要通过`malloc`、`realloc`和`new`等从堆中分配的一块内存，使用完必须手动调用`free`或`delete`删除。如果程序设计错误导致没有释放，此后这块内存将不会被使用，就会产生堆内存泄露。
2. **系统资源泄露**：主要指程序使用系统分配的资源比如`bitmap`、`handle`、`socket`等没有使用相应的函数释放掉，导致系统资源的浪费，严重可导致系统效能降低，系统运行不稳定。
3. **没有将基类的析构函数定义为虚函数**：当基类指向子类对象时，如果基类的析构函数不是虚函数，那么子类的析构函数将不会被调用，子类资源没有正确释放造成内存泄露。

### C++11 的三种内存序

C++11 标准引入了一套新的内存模型，这套模型中共有三种模型，分别为 sequentially-consistent 模型、acquire-release 模型和 relaxed 模型。三种模型对内存序的约束力是不一样的，sequentially-consistent 的约束力最强，但是执行效率也最低。relaxed 模型约束力最差，执行效率最高。acquire-release 模型约束力居中，属于半约束，执行效率也居中。

#### relaxed 内存序模型

relaxed 内存序模型允许编译器对代码的任意优化和重排，也允许 CPU 的指令重排，relaxed 唯一保证的是原子变量上的操作都是原子性的，即一个操作不会被中断，是排他性的，只有当一个操作完成后，才能执行另一个操作，即使是多线程。但是其他方面就不能保证了。

```c++
#include <atomic>
#include <thread>
#include <assert.h>

std::atomic<bool> x, y;
std::atomic<int> z;

void write_x_then_y()
{
	x.store(true, std::memory_order_relaxed); // 1
	y.store(true, std::memory_order_relaxed); // 2
}

void read_y_then_x()
{
	while(!y.load(std::memory_order_relaxed)); // 3
	if(x.load(std::memory_order_relaxed)) // 4
		++z;
}

int main()
{
	x = false;
	y = false;
	z = 0;
	std::thread a(write_x_then_y);
	std::thread b(read_y_then_x);
	a.join();
	b.join();
	assert(z.load()!= 0); // 5
}
```

上述代码中，我们可以保证在表达式 3 处跳出循环时，表达式 2 一定是已经执行了的，也就是表达式 2 happences-before 表达式 3 。但是由于使用的是 relaxed 内存序模型，所以表达式 1 没有 sequenced-before 表达式 2 ，表达式 3 也没有 sequenced-before 表达式 4 。因此，表达式 1 并没有 happens-before 表达式 4 ，因此最终无法确定表达式 4 一定会在表达式 1 被执行前执行，最终导致 z 的值可能仍然为 0 。更准确的说是：**表达式 4 在执行的时候，其所属线程可能还看不到另一个线程中表达式 1 对 x 值的修改动作**。

#### acquire-release 内存序模型

当原子变量同步点的 store 操作是 `memory_order_release` 或 `memory_order_acq_rel` 时，而对应的另一个同步点的 load 操作是 `memory_order_acquire` 或 `memory_order_acq_rel` 或 `memory_order_consume` 时，此时就是 acquire-release 内存序模型。标准规定：

1. **在 release 之前的所有 store 操作绝不会重排到（不管是编译器对代码的重排还是 CPU 指令重排）此 release 对应的操作之后**，也就是说如果 release 对应的 store 操作完成了，则 C++ 标准能够保证此 release 之前的所有 store 操作肯定已经先完成了，或者说可被感知了。
2. **在 acquire 之后的所有 load 操作或者 store 操作绝对不会重排到此 acquire 对应的操作之前**，也就是说只有当执行完此 acquire 对应的 load 操作之后，才会执行后续的读操作或者写操作。

```c++
// 这里的变量既有普通全局变量，又有原子类型的全局变量
int a = 0;
float b = 0.0;
short c = 0.0;
double d = 0.0;
char e = 's';
std::atomic<int> ai{0};
std::atomic<bool> go{false};

void write()
{
	int t = 1; //1
	a = t + 1; // 2
	b = 45.9; // 3
	c = 25; // 4
	ai.store(45, std::memory_order_relaxed); // 5
	go.store(true, std::memory_order_release); // 6
	d = 10.0; // 7
	e = 'g'; // 8
}

void read()
{
	std::cout << a << std::endl; // 9
	while (!g.load(std::memory_order_acquire)); // 10
	std::cout << b << c << ai << std::endl; // 11
}
```

表达式 6 处的 `std::memory_order_release` 能够保证上面的 1，2，3，4，5 表达式的执行一定是在表达式 6 之前完成。一旦 `go` 的值变成 `true` 了，那么可以肯定 1，2，3，4，5 表达式所对应的值也已经存储完成了，且其他线程是能够获取到这些改变后的值的，而不会因为在 Cache 中没有同步而造成不一样的情况（当然只有当检测到 `go` 位 `true` 之后才能如此确定）。不过，对于 1，2，3，4，5 这几个表达式，它们 5 个之间的执行顺序可以任由编译器重排或者处理器乱序执行，它们 5 个相互之间是无约束的。此外，对于表达式 7 和 8 来说，它俩就没有限制，它俩可以任由编译器重排，且可以重排到表达式 6 之上。release 内存序只对其前面的写操作有作用。

#### sequence-consistent 内存序模型

这种内存模型具有最强约束力，它不允许编译器对相关变量进行重排序，并且，它会在 CPU 的各个 Cache 之间产生大量的同步，以产生一致性的顺序，因此其效率也是最低的。其核心思想是：**任何线程中使用了 `acq_rel` 标记的原子变量的内存操作对于其他任何线程都是可感知的**。也就是说，如果使用了 `acq_rel` 的内存操作 A 在线程 1 中被执行了，则其他任何线程都能感知到操作 A 对原子变量的值的修改，而不会因为值缓存在 store-buffer 中而无法感知。

从内存模型规则的角度来看的话，不管是 load 操作还是 store 操作，只要是用了此内存序标记，其前面的任何操作都不会重排到此操作的后面（当然其前面的那些操作相互之间是可以重排的，无影响，类似于 acquire-release 语义），且此操作后面的任何操作都不会重排到此操作的前面（同理，此操作后面的那些操作相互之间可以重排），且一旦某个内存操作完成了，其他任何线程都能感知到。

```c++
#include <atomic>
#include <thread>
#include <assert.h>

std::atomic<bool> x,y;
std::atomic<int> z;

void write_x()
{
	x.store(true, std::memory_order_seq_cst); // 1
}

void write_y()
{
	y.store(true, std::memory_order_seq_cst); // 2
}

void read_x_then_y()
{
	while(!x.load(std::memory_order_seq_cst)); // 3
	if(y.load(std::memory_order_seq_cst)) // 4
		++z;
}

void read_y_then_x()
{
	while(!y.load(std::memory_order_seq_cst)); // 5
	if(x.load(std::memory_order_seq_cst)) // 6
		++z;
}

int main()
{
	x = false;
	y = false;
	z = 0;
	
	std::thread a(write_x);
	std::thread b(write_y);
	std::thread c(read_x_then_y);
	std::thread d(read_y_then_x);
	
	a.join();
	b.join();
	c.join();
	d.join();
	
	assert(z.load() != 0); // 7
}
```

## 析构函数

### 析构函数的作用

当对象结束其生命周期后，系统会自动执行析构函数。只能有一个析构函数，不能重载。如果用户没有编写析构函数，编译系统会自动生成一个缺省的析构函数==（即使自定义了析构函数，编译器也总是会为我们合成一个析构函数，执行时会先调用自定义的析构函数再调用合成的析构函数）==，它不进行任何操作。

### 为什么析构函数必须是虚函数？为什么默认的析构函数不是虚函数？

将可能会被继承的父类的析构函数设置为虚函数，可以保证当我们`new`一个子类，然后使用基类指针指向该子类对象，**释放基类指针时可以释放掉子类的空间**，防止内存泄露。

c++默认的析构函数不是虚函数是因为虚函数需要额外的虚函数表和虚表指针，占用额外的内存。而对于不会被继承的类来说，其析构函数如果是虚函数，就会**浪费内存**。

## 静态多态和动态多态

### 动态多态的设计思想

对于相关的对象类型，确定它们之间的一个共同功能集，然后在基类中，把这些共同的功能声明为多个公共的虚函数接口。各个子类重写这些虚函数，以完成具体的功能。客户端的代码（操作函数）通过**指向基类的引用或指针**来操作这些对象，对虚函数的调用会**自动绑定到实际提供的子类对象上**去。

从上面的定义也可以看出，由于有了虚函数，因此动态多态是在运行时完成的，也可以叫做**运行期多态**，这造就了动态多态机制在处理异质对象集合时的强大威力（当然，也有了一点点性能损失）。

```c++
namespace DynamicPoly
{
    class Geometry
    {
    public:
        virtual void Draw()const = 0;
    };

    class Line : public Geometry
    {
    public:
        virtual void Draw()const{    std::cout << "Line Draw()\n";    }
    };

    class Circle : public Geometry
    {
    public:
        virtual void Draw()const{    std::cout << "Circle Draw()\n";    }
    };

    class Rectangle : public Geometry
    {
    public:
        virtual void Draw()const{    std::cout << "Rectangle Draw()\n";    }
    };

    void DrawGeometry(const Geometry *geo)
    {
        geo->Draw();
    }
    
    void DrawGeometry(std::vector<DynamicPoly::Geometry*> vecGeo)
    {
        const size_t size = vecGeo.size();
        for(size_t i = 0; i < size; ++i)
            vecGeo[i]->Draw();
    }
}

void test_dynamic_polymorphism()
{
    DynamicPoly::Line line;
    DynamicPoly::Circle circle;
    DynamicPoly::Rectangle rect;
    DynamicPoly::DrawGeometry(&circle);


    std::vector<DynamicPoly::Geometry*> vec;
    vec.push_back(&line);
    vec.push_back(&circle);
    vec.push_back(&rect);
    DynamicPoly::DrawGeometry(vec);
}
```

### 静态多态的设计思想

对于相关的对象类型，直接实现它们各自的定义，不需要共有基类，甚至可以没有任何关系。只需要各个具体类的实现中要求相同的接口声明，这里的接口称之为隐式接口。客户端把操作这些对象的函数定义为模板，当需要操作什么类型的对象时，直接对模板指定该类型实参即可（或通过实参演绎获得）。

相对于面向对象编程中，以显式接口和运行期多态（虚函数）实现动态多态，在模板编程及泛型编程中，是以隐式接口和编译器多态来实现静态多态。

```c++
namespace StaticPoly
{
    class Line
    {
    public:
        void Draw()const{    std::cout << "Line Draw()\n";    }
    };

    class Circle
    {
    public:
        void Draw(const char* name=NULL)const{    std::cout << "Circle Draw()\n";    }
    };

    class Rectangle
    {
    public:
        void Draw(int i = 0)const{    std::cout << "Rectangle Draw()\n";    }
    };

    template<typename Geometry>
    void DrawGeometry(const Geometry& geo)
    {
        geo.Draw();
    }

    template<typename Geometry>
    void DrawGeometry(std::vector<Geometry> vecGeo)
    {
        const size_t size = vecGeo.size();
        for(size_t i = 0; i < size; ++i)
            vecGeo[i].Draw();
    }
}

void test_static_polymorphism()
{
    StaticPoly::Line line;
    StaticPoly::Circle circle;
    StaticPoly::Rectangle rect;
    StaticPoly::DrawGeometry(circle);

    std::vector<StaticPoly::Line> vecLines;
    StaticPoly::Line line2;
    StaticPoly::Line line3;
    vecLines.push_back(line);
    vecLines.push_back(line2);
    vecLines.push_back(line3);
    //vecLines.push_back(&circle);  //编译错误，已不再能够处理异质对象
    //vecLines.push_back(&rect);    //编译错误，已不再能够处理异质对象
    StaticPoly::DrawGeometry(vecLines);

    std::vector<StaticPoly::Circle> vecCircles;
    vecCircles.push_back(circle);
    StaticPoly::DrawGeometry(circle);
}
```

### 静态多态和动态多态的比较

1. 静态多态
   - 由于静态多态是在编译器完成的，因此效率较高，编译器也可以进行优化。
   - 有很强的适配性和松耦合性，比如可以通过偏特化、全特化来处理特殊类型。
   - 最重要的一点是静态多态通过模块编程为C++带来了泛型设计的概念，比如强大的STL库。
   - 由于是模块来实现静态多态，因此模板的不足也就是静态多态的劣势，比如调试困难、编译耗时、代码膨胀、编译器支持的兼容性、不能够处理异质对象集合。
2. 动态多态
   - OO设计，对客观世界的直觉认识。
   - 实现与接口分离，可复用。
   - 处理同一继承体系下异质对象集合的强大威力。
   - 运行期绑定，导致一定程度的运行时开销。
   - 编译器无法对虚函数进行优化。
   - 笨重的类继承体系，对接口的修改影响整个类层次
3. 不同点
   - 本质不同。静态多态在编译期决定，由模板具现完成。而动态多态在运行期决定，由继承、虚函数实现。
   - 动态多态中接口是显式的，以函数签名为中心，多态通过虚函数在运行期实现。静态多态中接口是隐式的，以有效表达式为中心，多态通过模板具现在编译期完成。
4. 相同点
   - 都能实现多态性。
   - 都能使接口和实现分离。一个是模板定义接口，类型参数定义实现。一个是基类虚函数定义接口，继承类负责实现。

### 重载、重写和重定义

#### 重写（override）

override是重写（覆盖）了一个方法，以实现不同的功能。一般用于子类在继承父类时，重写（覆盖）父类中的方法。函数特征相同，但是具体实现不同。

重写需要注意：

- 被重写的函数不能是static的，必须是virtual的
- 重写函数必须有相同的类型，名称和参数列表
- 重写函数的访问修饰符可以不同。尽管virtual是private的，派生类中重写改写为public、protect也是可以的

#### 重载（overload）

overload是重载，一般是在一个类实现若干重载的方法，这些**方法的名称相同而参数形式不同**。但是不能靠返回类型来判断。

重载需要注意：

- 位于同一个类中
- 函数的名字必须相同
- 形参列表不同
- 若一个重载版本的函数面前有virtual修饰，则表示他是虚函数，但他也是属于重载的一个版本
- 不同的构造函数(无参构造、有参构造、拷贝构造）是重载的应用

#### 重定义（redefining）

派生类对基类的成员函数重新定义，即派生类定义了某个函数，该函数的名字与基类中函数名字一样。

重定义也叫做隐藏，**子类重定义父类中有相同名称的非虚函数**（参数可以不同）。如果一个类，存在和父类相同的函数，那么这个类将会覆盖其父类的方法，除非你在调用的时候，强制转换为父类类型，否则试图对子类和父类做类似重载的调用时不能成功的。

重定义需要注意：

- 不在同一个作用域（分别位于基类、派生类）
- 函数的名字必须相同
- 对函数的返回值、形参列表无要求
- 若派生类定义该函数与基类的成员函数完全一样（返回值、形参列表均相同），且基类的该函数为virtual，则属于派生类重写基类的虚函数
- 若重新定义了基类中的一个重载函数，则在派生类中，基类中该名字函数（即其他所有重载版本）都会被自动隐藏，包括同名的虚函数

## printf 函数的可变长参数原理

利用函数栈中，函数的参数是从右往左依次进栈的。又因为栈的增长方向是由高地址到低地址，所以函数的第一个参数的地址是所有参数中最低的，我们只要知道参数的类型，就可以通过这个地址来顺序访问函数的参数。

注意，函数的参数并不全是从右往左依次进栈的，可能在 x86_64 的编译器里面，前面几个参数是寄存器直接传递，后面的参数才是从右往左依次进栈。

## 浅拷贝和深拷贝

浅拷贝是将原始对象中的数据型字段拷贝到新对象中去，将引用型字段的引用复制到新对象中去，不把引用的对象复制进去，所以原始对象和新对象引用同一对象，新对象中的引用型字段发生变化会导致原始对象中的对应字段也发生变化。

深拷贝是在引用方面不同，深拷贝就是创建一个新的和原始字段的内容相同的字段，是两个一样大的数据段，所以两者的引用是不同的，之后的新对象中的引用型字段发生改变，不会引起原始对象中的字段发生改变。

## 虚函数和虚函数表

### 类的虚表

每个包含了虚函数的类都包含一个虚表。

我们知道，当一个类（A）继承另一个类（B）时，类 A 会继承类 B 的函数的调用权。所以如果一个基类包含了虚函数，那么其继承类也可调用这些虚函数，换句话说，一个类继承了包含虚函数的基类，那么这个类也拥有自己的虚表。

我们来看以下的代码。类 A 包含虚函数 `vfunc1` ， `vfunc2` ，由于类 A 包含虚函数，故类 A 拥有一个虚表。

```c++
class A
{
public:
    virtual void vfunc1();
    virtual void vfunc2();
    void func1();
    void func2();
private:
    int m_data1, m_data2;
};
```

类 A 的虚表如图所示。

![img](https://pic3.zhimg.com/80/v2-e864f4fe6a480b3230a5c9aebd7df996_1440w.jpg)

**虚表是一个指针数组，其元素是虚函数的指针，每个元素对应一个虚函数的函数指针**。需要指出的是，普通的函数即非虚函数，其调用并不需要经过虚表，所以虚表的元素并不包括普通函数的函数指针。虚表内的条目，即虚函数指针的赋值发生在编译器的编译阶段，也就是说**在代码的编译阶段，虚表就可以构造出来了**。

### 虚表指针

虚表是属于类的，而不是属于某个具体的对象，一个类只需要一个虚表即可。同一个类的所有对象都使用同一个虚表。

为了指定对象的虚表，对象内部包含一个虚表的指针，来指向自己所使用的虚表。为了让每个包含虚表的类的对象都拥有一个虚表指针，编译器在类中添加了一个指针，`*__vptr`，用来指向虚表。这样，当类的对象在创建时便拥有了这个指针，且这个指针的值会自动被设置为指向类的虚表。

<img src="https://pic2.zhimg.com/80/v2-0fceb07713e411d48b4c361452129585_720w.jpg" alt="img" style="zoom: 67%;" />

上面指出，一个继承类的基类如果包含虚函数，那个这个继承类也有拥有自己的虚表，故这个继承类的对象也包含一个虚表指针，用来指向它的虚表。

### 动态绑定

```c++
class A
{
public:
    virtual void vfunc1();
    virtual void vfunc2();
    void func1();
    void func2();
private:
    int m_data1, m_data2;
};

class B : public A
{
public:
    virtual void vfunc1();
    void func1();
private:
    int m_data3;
};

class C : public B
{
public:
    virtual void vfunc2();
    void func2();
private:
    int m_data1, m_data4;
};
```

类 A 是基类，类 B 继承类 A ，类 C 又继承类 B 。类 A ，类 B ，类 C ，其对象模型如下图所示。

<img src="https://pic3.zhimg.com/80/v2-dfe4aefdee7e06cf3151b57492ed42a2_1440w.jpg" alt="img" style="zoom: 33%;" />

由于这三个类都有虚函数，故编译器为每个类都创建了一个虚表，即类 A 的虚表（A vtbl），类 B 的虚表（B vtbl），类 C 的虚表（C vtbl）。类 A ，类 B ，类 C 的对象都拥有一个虚表指针，`*__vptr`，用来指向自己所属类的虚表。

类 A 包括两个虚函数，故 A vtbl 包含两个指针，分别指向 `A::vfunc1()` 和 `A::vfunc2()` 。

类 B 继承于类 A ，故类 B 可以调用类 A 的函数，但由于类 B 重写了 `B::vfunc1()` 函数，故 B vtbl 的两个指针分别指向 `B::vfunc1()` 和 `A::vfunc2()` 。

类 C 继承于类 B ，故类 C 可以调用类 B 的函数，但由于类 C 重写了 `C::vfunc2()` 函数，故 C vtbl 的两个指针分别指向 `B::vfunc1()` （指向继承的最近的一个类的函数）和 `C::vfunc2()` 。

```c++
int main()
{
	B bObject;
    A *p = &bObject;
    p->vfunc1();
}
```

程序在执行 `p->vfunc1()` 时，会发现 `p` 是个指针，且调用的函数是虚函数，接下来便会进行以下的步骤。

首先，根据虚表指针 `p->__vptr` 来访问对象 `bObject `对应的虚表。虽然指针 `p` 是基类 `A*` 类型，但是`*__vptr` 也是基类的一部分，所以可以通过 `p->__vptr` 可以访问到对象对应的虚表。

然后，在虚表中查找所调用的函数对应的条目。由于虚表在编译阶段就可以构造出来了，所以可以根据所调用的函数定位到虚表中的对应条目。对于 `p->vfunc1()` 的调用， B vtbl 的第一项即是 `vfunc1` 对应的条目。

最后，根据虚表中找到的函数指针，调用函数。从图可以看到， B vtbl 的第一项指向 `B::vfunc1()` ，所以 `p->vfunc1()` 实质会调用 `B::vfunc1()` 函数。

## 结构体的字节对齐

1. **变量**的**起始地址**能够被其对齐值整除，结构体变量的对齐值为最宽的成员大小。
2. 结构体**每个成员相对于起始地址的偏移**能够被其**自身对齐值**整除，如果不能则在**前一个成员后面**补充字节。
3. 结构体总大小能够被**最宽的成员的大小**整除，如果不能则在**后面**补充字节。

==此外编译器还有默认对齐值，一般是4（结构体的实际对齐值会取结构体对齐值和编译器默认对齐值中较小的那个）。==

**字节对齐的意义：**

1. 为了减少使用的内存。
2. 为了提升数据读取的效率。

## char* 和 string

### char* 和 string 的区别

- string 的内存管理是由系统处理的，除非系统内存池用完，不然不会出现内存问题。

- char* 的内存管理由用户自己处理，很容易出现内存不足的问题。

- 用 string 可以使用各种成员函数来处理串的每个字符，方便。

- 用 char* 来处理串就要自己编写函数来完成处理。

  **注意：`char *s = "string"`的内容是不可以改的，`char s[10] = "string"`的内容可以改。**

### char* 和 string 的转换

```c++
#include <iostream>
#include <stdio.h>
using namespace std;

int main()
{
    string s = "xiaoming";
    const char *a = s.c_str(); // 去掉const会显示编译错误
    const char *b = s.data();
    printf("a:[%s],b:[%s]\n", a, b);
}
```

```c++
#include <iostream>
#include <stdio.h>
using namespace std;

int main()
{
    char *a = "xiaoming";
    string s;
    s = a;
    printf("%s\n", s.c_str());
}
```

## new/delete 和 malloc/free 的区别

- `new`操作符从**自由存储区**（free store）上为对象动态分配内存空间，而`malloc`函数从**堆**上动态分配内存。自由存储区是C++基于`new`操作符的一个抽象概念，凡是通过`new`操作符进行内存申请，该内存即为自由存储区。而堆是操作系统中的术语，是操作系统所维护的一块特殊内存，用于程序的内存动态分配，C语言使用`malloc`从堆上分配内存，使用`free`释放已分配的对应内存。那么自由存储区是否能够是堆（问题等价于`new`是否能在堆上动态分配内存），这取决于`operator new`的实现细节。自由存储区不仅可以是堆，还可以是静态存储区，这都看`operator new`在哪里为对象分配内存。
- `new`操作符内存分配成功时，返回的是对象类型的指针，类型严格与对象匹配，**无须进行类型转换**，故`new`是符合类型安全性的操作符。而`malloc`内存分配成功则是返回`void*` ，需要通过**强制类型转换**将`void*`指针转换成我们需要的类型。
- `new`内存分配失败时，会抛出`bac_alloc`**异常**，会返回NULL；`malloc`分配内存失败时返回NULL。
- 使用`new`操作符申请内存分配时**无须指定内存块的大小**，编译器会根据类型信息自行计算，而`malloc`则需要**显式地指出所需内存的尺寸**。
- `new`，`delete`会**调用对象的构造和析构函数**同时申请或释放内存，而`malloc`，`free`则**不会调用构造或析构函数**。
- C++提供了`new[]`与`delete[]`来专门处理数组类型。
- `operator new`/`operator delete`的实现可以基于`malloc`，而`malloc`的实现不可以去调用`new`。

## RTTI

运行时类型信息，它提供了运行时确定对象类型的方法。

1. typeid 函数

   对于 C++ 的内置数据类型或者自己创建的类对象，typeid 可以方便的输出它们的数据类型。但是要注意，**当类中不存在虚函数的时候，typeid 是编译时期的事情。当类中存在虚函数的时候，typeid 就是运行时期的事情。**

2. type_info 类里面的比较运算符

   比如 `typeid(*ptr)==typeid(ClassA)` 。

3. dynamic_cast 机制

   转换失败的话会抛出 bad_cast 异常。

## C++ 如何处理返回值

1. 不要返回局部对象的引用或指针。
2. 引用返回左值，其它返回类型得到右值。
3. main 函数返回值中，0 表示成功。

## 顶层 const 和底层 const

用顶层表示指针本身是个常量，底层表示指针所指向的对象是个常量。更一般的是，顶层 const 可以表示任意的对象是常量，底层 const 则与指针和引用等复合类型有关，比较特殊的是，指针类型既可以是顶层 const 也可以是底层 const 或者二者兼备。

当执行对象的拷贝操作时，拷入和拷出的对象必须具有相同的底层 const 资格，或者两个对象的数据类型必须能够转换，一般来说，非常量可以转化为常量，反之不行。

底层 const 可以实现函数的重载，但是顶层 const 不行。比如：

```c++
Record lookup(Phone*);
Record lookup(const Phone*); // 底层const实现了函数的重载
```

**为什么不能在一个常量对象中调用非常量成员函数？**

因为在默认情况下，this 的类型是指向类的非常量版本的常量指针（意思是 this 的值不能改变，永远指向那个对象，即“常量指针”，但是被 this 指向的对象本身是可以改变的，因为是非常量版本，这里 this 相当于是顶层 const ），而 this 尽管是隐式的，它仍然需要遵循初始化规则，**普通成员函数的隐式参数之一是一个底层非 const 指针**，在默认情况下我们无法把一个底层 const 的 this 指针转化为非 const 的 this 指针，因此我们不能在常量对象上调用普通的成员函数。因此在上例中，形参列表后的 const 就意味着默认 this 指针应该是一个底层 const，类型是 const ClassName&。而非常对象却可以调用常成员函数，因为底层非 const 可以默认转化为底层 const。

## STL

### STL 的基本组成

容器、迭代器、仿函数、算法、分配器、配接器。

分配器给容器分配存储空间，算法通过迭代器获取容器中的内容，仿函数可以协助算法完成各种操作，配接器用来套接适配仿函数。

### map 和 set 的区别，分别是怎么实现的？

map 和 set 都是**关联容器**，底层实现都是**红黑树**。区别在于：

- map 中的元素是 key-value 对，关键字起到索引的作用。set 是关键字的简单集合。

- set 的迭代器是 const 的，不允许修改元素的值。map 允许修改 value，不允许修改 key。

- map 支持下标操作，可以用 key 做下标。set 不支持。

### STL 中的 allocator

STL 的分配器用于封装 STL 容器在内存管理上的底层细节。在 c++ 中，其内存配置和释放如下：

`new`分两个阶段：（1）调用`operator new`配置内存；（2）调用对象的构造函数。

`delete`分两个阶段：（1）调用对象的析构函数；（2）调用`operator delete`释放内存。

new 操作将内存分配和对象构造组合在一起，而 **allocator 的意义在于将内存分配和构造分离**。这样就可以分配大块内存，而只在真正需要时才执行对象创建操作。

假设我们先申请 n 个对象，再根据情况逐一给对象赋值，如果内存分配和对象构造不分离可能带来的弊端如下：

1. 我们可能会创建一些用不到的对象；
2. 对象被赋值两次，一次是默认初始化时，一次是赋值时；
3. 没有默认构造函数的类甚至不能动态分配数组；

使用 allocator 之后，我们便可以解决上述问题。

为了精密分工，allocator 将两个阶段操作区分开：内存配置`allocate()`负责，内存释放`deallocate()`负责，对象构造`construct()`负责，对象析构`destroy()`负责。

同时为了提升内存管理效率，减少申请小内存造成的内存碎片问题，STL 采用了两级配置器，当分配空间大小超过128B 时，会使用第一级空间配置器，直接使用`malloc()`、`realloc()`、`free()`函数进行内存空间的分配和释放。当分配的空间大小小于 128B 时，将使用第二级空间配置器，采用内存池技术，通过空闲链表来管理内存。

```c++
allocator<string> alloc; // 构造allocator对象
auto const p = alloc.allocate(n); // 分配n个未初始化的string

// 在分配的内存处创建对象
auto q = p;
alloc.construct(q++, "hello");
alloc.construct(q++, 10, 'c');

// 将已构造的string销毁
while (q != p)
{
    alloc.destroy(--q);
}

// 将分配的n个string内存空间释放
alloc.deallocate(p, n);
```

### 为什么 allocator 不好用？

如果仔细观察，我们会发现很多商业引擎都没有使用 STL 中的容器和分配器，而是自己实现了相应的功能。这意味着 allocator 无法满足某些引擎开发一些定制化的需求：

1. allocator 内存对齐无法控制
2. allocator 难以应用内存池之类的优化机制
3. 绑定模板签名

### STL 的优化

### STL 迭代器删除元素

对于序列容器`vector`，`deque`来说，使用`erase(iterator)`删除当前迭代器元素后，后边每个元素的迭代器都会失效，但是后边每个元素都会往前移动一个位置，`erase(iterator)`会返回下一个有效的迭代器。

对于关联容器`map`，`set`来说，使用`erase(iterator)`删除当前迭代器元素后，当前元素的迭代器失效，但是由于内部是红黑树实现，删除当前元素的迭代器不会影响到下一个元素的迭代器。所以在调用`erase(iterator)`之前记录下一个元素的迭代器即可。

对于`list`来说，它使用了不连续分配的内存，并且它的`erase(iterator)`方法也会返回下一个有效的迭代器，因此上面两种方法都可以使用。

### vector 和 list 的区别

**vector：**

1. 连续存储的容器，动态数组，在堆上分配空间。
2. 底层是数组实现。
3. vector增加元素的时候如果没有剩余空间，会重新配置原有元素个数两倍的空间，将原空间元素复制到新空间，再向新空间增加元素，最后析构并释放原空间，之前的迭代器失效。
4. 访问的时间是O（1）。
5. 空间够的时候在最后插入很快，不够的时候涉及到内存申请和释放以及数据的拷贝。往中间插入数据也涉及到数据的拷贝。
6. 适用于经常随机访问且不经常对非尾部节点进行插入删除。

**list：**

1. 动态链表，在堆上分配空间，每插入一个元素都会分配空间，每删除一个元素都会释放空间。
2. 底层是双向链表实现。
3. 随机访问性能很差，只能快速访问头尾节点。
4. 插入和删除很快。
5. 适用于经常插入和删除数据。

### STL 中迭代器和指针的区别，有指针为什么还要迭代器？

迭代器提供一种方法顺序访问一个聚合对象中各个元素，而又不需要暴露该对象的内部表示。

迭代器不是指针，是类模板，但是它通过重载指针的一些操作符模拟了指针的一些功能。迭代器封装了指针，是一个可遍历STL容器内全部或部分元素的对象，提供了比指针更高级的行为，它可以根据不同类型的数据结构来实现不同的++和--等操作。

==迭代器返回的是对象引用而不是对象的值==，所以cout只能输出迭代器使用*取值后的值。

**iterator类的访问方式就是把不同集合类的访问逻辑抽象出来，使得不用暴露集合内部的结构而达到循环遍历集合的效果。**

### STL 中 resize 和 reserve 的区别

**resize：**改变当前容器内含有元素的数量。`v.resize(len)`中，如果原来`v.size()<len`，那么容器中新增`len-v.size()`个元素，默认值为0。当`push_back`元素的时候，则是在下标为`len`的位置添加，即此时容器的`v.size()==len+1`。

**reserver：**改变当前容器的最大容量，它不会生成元素，只是确定这个容器允许放入多少对象。如果`reserve(len)`的值大于当前的`capacity`，就会重新分配一个能存`len`个对象的空间，然后把之前的对象拷贝过来，销毁之前的内存。

## class 和 struct 的区别

## 类构造函数初始化列表和赋值的区别

## C++11 的可变参数模板

## C++11 的右值引用

## C++11 的 lambda

## C++ 中的函数签名

C++中的函数签名包含了一个函数的信息，包括**函数名、参数类型、参数个数、顺序以及它所在的类和命名空间**。普通函数签名并不包含函数返回值部分，如果两个函数仅仅只有函数返回值不同，那么系统是无法区分这两个函数的，此时编译器会提示语法错误。

函数签名用于识别不同的函数，函数的名字只是函数签名的一部分。在编译器及链接器处理符号时，使用某种名称修饰的方法，使得每个函数签名对应一个修饰后名称。**编译器在将C++源代码编译成目标文件时，会将函数和变量的名字进行修饰，形成符号名**，也就是说，C++的源代码编译后的目标文件中所使用的符号名是相应的函数和变量的修饰后名称。**C++编译器和链接器都使用符号来识别和处理函数和变量**，所以对于不同函数签名的函数，即使函数名相同，编译器和链接器都认为它们是不同的函数。

 不同的编译器厂商的名称修饰方法可能不同，所以不同的编译器对于同一个函数签名可能对应不同的修饰后名称。
# 计算机网络知识汇总

## TCP 怎么保证可靠性

- **数据分块：**应用数据被分割成 TCP 认为最适合发送的数据块。
- **序列号和确认应答：**TCP 给发送的每一个包进行编号，在传输的过程中，==每次接收方收到数据后，都会对传输方进行确认应答，即发送 ACK 报文，这个 ACK 报文当中带有对应的确认序列号==，告诉发送方成功接收了哪些数据以及下一次的数据从哪里开始发。除此之外，==接收方可以根据序列号对数据包进行排序，把有序数据传送给应用层，并丢弃重复的数据==。
- **校验和：** TCP 将==保持它首部和数据部分的检验和==。这是一个端到端的检验和，目的是==检测数据在传输过程中的任何变化==。如果收到报文段的检验和有差错，TCP 将丢弃这个报文段并且不确认收到此报文段。
- **流量控制：** TCP 连接的双方都有一个固定大小的缓冲空间，==发送方发送的数据量不能超过接收端缓冲区的大小==。当接收方来不及处理发送方的数据，会提示发送方降低发送的速率，防止产生丢包。TCP 通过滑动窗口协议来支持流量控制机制。
- **拥塞控制：** 当网络==某个节点发生拥塞时，减少数据的发送==。
- **ARQ协议：** 也是为了实现可靠传输的，它的基本原理就是==每发完一个分组就停止发送，等待对方确认==。在收到确认后再发下一个分组。
- **超时重传：** 当 TCP 发出一个报文段后，它启动一个定时器，等待目的端确认收到这个报文段。==如果超过某个时间还没有收到确认，将重发这个报文段==。

## TCP 三次握手和四次挥手的过程及原因

### 三次握手

![image.png](https://pic.leetcode-cn.com/1614160878-FiFlkq-image.png)

三次握手是 TCP 连接的建立过程。在握手之前，主动打开连接的客户端结束 CLOSE 阶段，被动打开的服务器也结束 CLOSE 阶段，并进入 LISTEN 阶段。随后进入三次握手阶段：

1. 首先客户端向服务器发送一个 SYN 包，并等待服务器确认，其中：
   - 标志位为 SYN，表示请求建立连接；
   - 序号为 Seq = x（x 一般为 1）；
   - 随后客户端进入 SYN-SENT 阶段。
2. 服务器接收到客户端发来的 SYN 包后，对该包进行确认后结束 LISTEN 阶段，并返回一段 TCP 报文，其中：
   - 标志位为 SYN 和 ACK，表示确认客户端的报文 Seq 序号有效，服务器能正常接收客户端发送的数据，并同意创建新连接；
   - 序号为 Seq = y；
   - 确认号为 Ack = x + 1，表示收到客户端的序号 Seq 并将其值加 1 作为自己确认号 Ack 的值，随后服务器端进入 SYN-RECV 阶段。
3. 客户端接收到发送的 SYN + ACK 包后，明确了从客户端到服务器的数据传输是正常的，从而结束 SYN-SENT 阶段。并返回最后一段报文。其中：
   - 标志位为 ACK，表示确认收到服务器端同意连接的信号；
   - 序号为 Seq = x + 1，表示收到服务器端的确认号 Ack，并将其值作为自己的序号值；
   - 确认号为 Ack= y + 1，表示收到服务器端序号 seq，并将其值加 1 作为自己的确认号 Ack 的值。
   - 随后客户端进入 ESTABLISHED。

当服务器端收到来自客户端确认收到服务器数据的报文后，得知从服务器到客户端的数据传输是正常的，从而结束 SYN-RECV 阶段，进入 ESTABLISHED 阶段，从而完成三次握手。

### 四次挥手

<img src="https://pic.leetcode-cn.com/1612459478-ajInIu-%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B.png" alt="四次挥手.png" style="zoom:50%;" />

四次挥手即 TCP 连接的释放，这里假设客户端主动释放连接。在挥手之前主动释放连接的客户端结束 ESTABLISHED 阶段，随后开始四次挥手：

1. 首先客户端向服务器发送一段 TCP 报文表明其想要释放 TCP 连接，其中：
   - 标记位为 FIN，表示请求释放连接；
   - 序号为 Seq = u；
   - 随后客户端进入 FIN-WAIT-1 阶段，即半关闭阶段，并且停止向服务端发送通信数据。
2. 服务器接收到客户端请求断开连接的 FIN 报文后，结束 ESTABLISHED 阶段，进入 CLOSE-WAIT 阶段并返回一段 TCP 报文，其中：
   - 标记位为 ACK，表示接收到客户端释放连接的请求；
   - 序号为 Seq = v；
   - 确认号为 Ack = u + 1，表示是在收到客户端报文的基础上，将其序号值加 1 作为本段报文确认号 Ack 的值；
   - 随后服务器开始准备释放服务器端到客户端方向上的连接。

客户端收到服务器发送过来的 TCP 报文后，确认服务器已经收到了客户端连接释放的请求，随后客户端结束 FIN-WAIT-1 阶段，进入 FIN-WAIT-2 阶段。

3. **服务器端在发出 ACK 确认报文后，服务器端会将遗留的待传数据传送给客户端**，待传输完成后即经过 CLOSE-WAIT 阶段，便做好了释放服务器端到客户端的连接准备，再次向客户端发出一段 TCP 报文，其中：
   - 标记位为 FIN 和 ACK，表示已经准备好释放连接了；
   - 序号为 Seq = w；
   - 确认号 Ack = u + 1，表示是在收到客户端报文的基础上，将其序号 Seq 的值加 1 作为本段报文确认号 Ack 的值。

随后服务器端结束 CLOSE-WAIT 阶段，进入 LAST-ACK 阶段。并且停止向客户端发送数据。

4. 客户端收到从服务器发来的 TCP 报文，确认了服务器已经做好释放连接的准备，于是结束 FIN-WAIT-2 阶段，进入 TIME-WAIT 阶段，并向服务器发送一段报文，其中：
   - 标记位为 ACK，表示接收到服务器准备好释放连接的信号；
   - 序号为 Seq= u + 1，表示是在已收到服务器报文的基础上，将其确认号 Ack 值作为本段序号的值；
   - 确认号为 Ack= w + 1，表示是在收到了服务器报文的基础上，将其序号 Seq 的值作为本段报文确认号的值。

**随后客户端开始在 TIME-WAIT 阶段等待 2 MSL**。服务器端收到从客户端发出的 TCP 报文之后结束 LAST-ACK 阶段，进入 CLOSED 阶段。由此正式确认关闭服务器端到客户端方向上的连接。客户端等待完 2 MSL 之后，结束 TIME-WAIT 阶段，进入 CLOSED 阶段，由此完成「四次挥手」。

### 如果三次握手的时候每次握手信息对方没有收到会怎么样

- 若第一次握手服务器未接收到客户端请求建立连接的数据包时，服务器不会进行任何相应的动作，而客户端由于在一段时间内没有收到服务器发来的确认报文， 因此会等待一段时间后重新发送 SYN 同步报文，若仍然没有回应，则**重复上述过程直到发送次数超过最大重传次数限制后，建立连接的系统调用会返回 -1**。
- 若第二次握手客户端未接收到服务器回应的 ACK 报文时，客户端会采取第一次握手失败时的动作，这里不再重复，**而服务器端此时将阻塞在 `accept()` 系统调用处等待 client 再次发送 ACK 报文**。
- 若第三次握手服务器未接收到客户端发送过来的 ACK 报文，同样会**采取类似于客户端的超时重传机制，若重传次数超过限制后仍然没有回应，则 `accept()` 系统调用返回 -1，服务器端连接建立失败**。但此时客户端认为自己已经连接成功了，因此开始向服务器端发送数据，但是服务器端的 accept() 系统调用已返回，此时没有在监听状态。因此**服务器端接收到来自客户端发送来的数据时会发送 RST 报文给客户端，消除客户端单方面建立连接的状态**。

### 为什么要进行三次握手

三次握手的主要目的是**确认自己和对方的发送和接收都是正常的，从而保证了双方能够进行可靠通信**。若采用两次握手，当第二次握手后就建立连接的话，此时客户端知道服务器能够正常接收到自己发送的数据，而服务器并不知道客户端是否能够收到自己发送的数据。

我们知道网络往往是非理想状态的（存在丢包和延迟），当客户端发起创建连接的请求时，如果服务器直接创建了这个连接并返回包含 SYN、ACK 和 Seq 等内容的数据包给客户端，这个数据包因为网络传输的原因丢失了，丢失之后客户端就一直接收不到返回的数据包。由于客户端可能设置了一个超时时间，一段时间后就关闭了连接建立的请求，再重新发起新的请求，而服务器端是不知道的，如果没有第三次握手告诉服务器客户端能否收到服务器传输的数据的话，服务器端的端口就会一直开着，等到客户端因超时重新发出请求时，服务器就会重新开启一个端口连接。长此以往， **这样的端口越来越多，就会造成服务器开销的浪费**。

### 为什么要四次挥手

释放 TCP 连接时之所以需要四次挥手，是因为 FIN 释放连接报文和 ACK 确认接收报文是分别在两次握手中传输的。 **当主动方在数据传送结束后发出连接释放的通知，由于被动方可能还有必要的数据要处理，所以会先返回 ACK 确认收到报文。当被动方也没有数据再发送的时候，则发出连接释放通知，对方确认后才完全关闭 TCP 连接**。

举个例子：A 和 B 打电话，通话即将结束后，A 说“我没啥要说的了”，B回答“我知道了”，但是 B 可能还会有要说的话，A 不能要求 B 跟着自己的节奏结束通话，于是 B 可能又巴拉巴拉说了一通，最后 B 说“我说完了”，A 回答“知道了”，这样通话才算结束。

### CLOSE-WAIT 和 TIME-WAIT 的状态和意义

在服务器收到客户端关闭连接的请求并告诉客户端自己已经成功收到了该请求之后，服务器进入了 CLOSE-WAIT 状态，然而此时有可能服务端还有一些数据没有传输完成，因此不能立即关闭连接，**而 CLOSE-WAIT 状态就是为了保证服务器在关闭连接之前将待发送的数据发送完成**。

TIME-WAIT 发生在第四次挥手，当客户端向服务端发送 ACK 确认报文后进入该状态，若取消该状态，即客户端在收到服务端的 FIN 报文后立即关闭连接，此时服务端相应的端口并没有关闭，若客户端在相同的端口立即建立新的连接，则有可能接收到上一次连接中残留的数据包，可能会导致不可预料的异常出现。除此之外，假设客户端最后一次发送的 ACK 包在传输的时候丢失了，由于 TCP 协议的超时重传机制，服务端将重发 FIN 报文，**若客户端并没有维持 TIME-WAIT 状态而直接关闭的话，当收到服务端重新发送的 FIN 包时，客户端就会用 RST 包来响应服务端，这将会使得对方认为是有错误发生**，然而其实只是正常的关闭连接过程，并没有出现异常情况。

### TIME_WAIT 状态会导致什么问题，怎么解决

我们考虑高并发短连接的业务场景，在高并发短连接的 TCP 服务器上，当服务器处理完请求后主动请求关闭连接，这样**服务器上会有大量的连接处于 TIME_WAIT 状态，服务器维护每一个连接需要一个 socket，也就是每个连接会占用一个文件描述符，而文件描述符的使用是有上限的，如果持续高并发，会导致一些正常的 连接失败**。

解决方案：

服务器可以**设置 SO_REUSEADDR 套接字选项来通知内核，如果端口被占用，但 TCP 连接位于 TIME_WAIT 状态时可以重用端口**。如果你的服务器程序停止后想立即重启，而新的套接字依旧希望使用同一端口，此时 SO_REUSEADDR 选项就可以避免 TIME-WAIT 状态。

也可以采用长连接的方式减少 TCP 的连接与断开，在长连接的业务中往往不需要考虑 TIME-WAIT 状态，但其实在长连接的业务中并发量一般不会太高。

### TIME_WAIT 为什么是 2MSL

当客户端发出最后的 ACK 确认报文时，并不能确定服务器端能够收到该段报文。所以客户端在发送完 ACK 确认报文之后，会设置一个时长为 2 MSL 的计时器。MSL（Maximum Segment Lifetime），**指一段 TCP 报文在传输过程中的最大生命周期**。2 MSL 即是服务器端发出 FIN 报文和客户端发出的 ACK 确认报文所能保持有效的最大时长。

**若服务器在 1 MSL 内没有收到客户端发出的 ACK 确认报文，再次向客户端发出 FIN 报文**。如果客户端在 2 MSL 内收到了服务器再次发来的 FIN 报文，说明服务器由于一些原因并没有收到客户端发出的 ACK 确认报文。客户端将再次向服务器发出 ACK 确认报文，并重新开始 2 MSL 的计时。

若客户端在 2MSL 内没有再次收到服务器发送的 FIN 报文，则说明服务器正常接收到客户端 ACK 确认报文，客户端可以进入 CLOSE 阶段，即完成四次挥手。

所以客户端要经历 2 MSL 时长的 TIME-WAIT 阶段，为的是**确认服务器能否接收到客户端发出的 ACK 确认报文**。

## TCP

### TCP 协议中的定时器

TCP 中有七种计时器，分别为：

1. **建立连接定时器：**顾名思义，该定时器是在建立 TCP 连接的时候使用的，在 TCP 三次握手的过程中，发送方发送 SYN 时，会启动一个定时器（默认为 3 秒），==若 SYN 包丢失了，那么 3 秒以后会重新发送 SYN 包，直到达到重传次数==。

2. **重传定时器：**该计时器主要用于 ==TCP 超时重传机制==中，当TCP 发送报文段时，就会创建特定报文的重传计时器，并可能出现两种情况：
   - 若在计时器截止之前发送方收到了接收方的 ACK 报文，则撤销该计时器；
   - 若计时器截止时间内并没有收到接收方的 ACK 报文，则发送方重传报文，并将计时器复位。

3. **坚持计时器：**我们知道 TCP 通过让接收方指明希望从发送方接收的数据字节数（窗口大小）来进行流量控制，当接收端的接收窗口满时，接收端会告诉发送端此时窗口已满，请停止发送数据。此时发送端和接收端的窗口大小均为0，直到窗口变为非0时，接收端将发送一个确认 ACK 告诉发送端可以再次发送数据，但是该报文有可能在传输时丢失。若该 ACK 报文丢失，则双方可能会一直等待下去，为了避免这种死锁情况的发生，==发送方使用一个坚持定时器来周期性地向接收方发送探测报文段，以查看接收方窗口是否变大==。

4. **延迟应答计时器：**延迟应答也被称为捎带 ACK，这个定时器是在延迟应答的时候使用的，为了提高网络传输的效率，==当服务器接收到客户端的数据后，不是立即回 ACK 给客户端，而是等一段时间，这样如果服务端有数据需要发送给客户端的话，就可以把数据和 ACK 一起发送给客户端了==。

5. **保活定时器：**该定时器是在建立 TCP 连接时指定 SO_KEEPLIVE 时才会生效，==当发送方和接收方长时间没有进行数据交互时，该定时器可以用于确定对端是否还活着==。

6. **FIN_WAIT_2 定时器：**当主动请求关闭的一方发送 FIN 报文给接收端并且收到其对 FIN 的确认 ACK 后进入 FIN_WAIT_2 状态。如果这个时候因为网络突然断掉、被动关闭的一端宕机等原因，导致请求方没有收到接收方发来的 FIN，主动关闭的一方会一直等待。该定时器的作用就是为了避免这种情况的发生。==当该定时器超时的时候，请求关闭方将不再等待，直接释放连接==。

7. **TIME_WAIT 定时器：**我们知道在 TCP 四次挥手中，发送方在最后一次挥手之后会进入 TIME_WAIT 状态，不直接进入 CLOSE 状态的主要原因是被动关闭方万一在超时时间内没有收到最后一个 ACK，则会重发最后的 FIN，2 MSL（报文段最大生存时间）等待时间==保证了重发的 FIN 会被主动关闭的一端收到且重新发送最后一个 ACK== 。还有一个原因是在这 2 MSL 的时间段内任何迟到的报文段会被接收方丢弃，从而防止老的 TCP 连接的包在新的 TCP 连接里面出现。

### TCP 超时重传

发送方在发送一次数据后就开启一个定时器，在一定时间内如果没有得到发送数据包的 ACK 报文，那么就重新发送数据，在达到一定次数还没有成功的话就放弃重传并发送一个复位信号。其中超时时间的计算是超时的核心，而定时时间的确定往往需要进行适当的权衡，因为当**定时时间过长会造成网络利用率不高，定时太短会造成多次重传，使得网络阻塞**。在 TCP 连接过程中，会参考当前的网络状况从而找到一个合适的超时时间。

### TCP 停止等待协议

停止等待协议是为了实现 TCP 可靠传输而提出的一种相对简单的协议，该协议指的是**发送方每发完一组数据后，直到收到接收方的确认信号才继续发送下一组数据**。我们通过四种情形来帮助理解停等协议是如何实现可靠传输的：

<img src="https://pic.leetcode-cn.com/1612460049-DzVGiO-%E6%97%A0%E5%B7%AE%E9%94%99%E5%92%8C%E8%B6%85%E6%97%B6%E9%87%8D%E4%BC%A0.png" alt="无差错和超时重传.png" style="zoom: 50%;" />

1. 无差错传输

   如上述左图所示，A 发送分组 Msg 1，发完就暂停发送，直到收到接收方确认收到 Msg 1 的报文后，继续发送 Msg 2，以此类推，该情形是通信中的一种理想状态。

2. 出现差错

   如上述右图所示，发送方发送的报文出现差错导致接收方不能正确接收数据，出现差错的情况主要分为两种：

   - 发送方发送的 Msg 1 在中途丢失了，接收方完全没收到数据。
   - 接收方收到 Msg 1 后检测出现了差错，直接丢弃 Msg 1。

上面两种情形，接收方都不会回任何消息给发送方，此时就会触发超时传输机制，即发送方在等待一段时间后仍然没有收到接收方的确认，就认为刚才发送的数据丢失了，因此重传前面发送过的数据。

<img src="https://pic.leetcode-cn.com/1612460087-MRLQIm-%E7%A1%AE%E8%AE%A4%E4%B8%A2%E5%A4%B1%E5%92%8C%E7%A1%AE%E8%AE%A4%E9%87%8D%E4%BC%A0.png" alt="确认丢失和确认重传.png" style="zoom:50%;" />

3. 确认丢失

   当接收方回应的 Msg 1 确认报文在传输过程中丢失，发送方无法接收到确认报文。于是发送方等待一段时间后重传 Msg 1，接收方将收到重复的 Msg1 数据包，此时接收方会丢弃掉这个重复报文并向发送方再次发送 Msg1 的确认报文。

4. 确认迟到

   当接收方回应的 Msg 1 确认报文由于网络各种原因导致发送方没有及时收到，此时发送方在超时重传机制的作用下再次发送了 Msg 数据包，接收方此时进行和确认丢失情形下相同的动作（丢弃重复的数据包并再次发送 Msg 1 确认报文）。发送方此时收到了接收方的确认数据包，于是继续进行数据发送。过了一段时间后，发送方收到了迟到的 Msg 1 确认包会直接丢弃。


### TCP 最大连接数限制

client 在每次发起 TCP 连接请求时，如果自己并不指定端口的话，系统会随机选择一个本地端口（local port），该端口是独占的，不能和其他 TCP 连接共享。TCP 端口的数据类型是 unsigned short，因此本地端口个数最大只有 65536，除了端口 0不能使用外，其他端口在空闲时都可以正常使用，这样可用端口最多有 65535 个。

### TCP 流量控制

所谓流量控制就是让发送方的发送速率不要太快，让接收方来得及接收。如果接收方来不及接收发送方发送的数据，那么就会有分组丢失。在 TCP 中利用可变长的滑动窗口机制可以很方便的在 TCP 连接上实现对发送方的流量控制。主要的方式是**接收方返回的 ACK 中会包含自己的接收窗口大小，以控制发送方此次发送的数据量大小**（发送窗口大小）。

基于 TCP 流量控制中的滑动窗口协议，我们知道接收方返回给发送方的 ACK 包中会包含自己的接收窗口大小，若接收窗口已满，此时接收方返回给发送方的接收窗口大小为 0，此时**发送方会等待接收方发送的窗口大小直到变为非 0** 为止，然而，接收方回应的 ACK 包是存在丢失的可能的，为了防止双方一直等待而出现死锁情况，此时就需要坚持计时器来辅助**发送方周期性地向接收方查询，以便发现窗口是否变大**，当发现窗口大小变为非零时，发送方便继续发送数据。

### TCP 拥塞控制

在实际的网络通信系统中，除了发送方和接收方外，还有路由器，交换机等复杂的网络传输线路，此时就需要拥塞控制。拥塞控制是作用于网络的，它是**防止过多的数据注入到网络中，避免出现网络负载过大的情况**。常用的解决方法有：慢开始和拥塞避免、快重传和快恢复。

1. 慢开始

   当发送方开始发送数据时，由于一开始不知道网络负荷情况，如果立即将大量的数据字节传输到网络中，那么就有可能引起网络拥塞。一个较好的方法是**在一开始发送少量的数据先探测一下网络状况，即由小到大的增大发送窗口**（拥塞窗口 cwnd ）。慢开始的慢指的是初始时令 cwnd 为 1，即一开始发送一个报文段。如果收到确认，则 cwnd = 2，之后每收到一个确认报文，就令 cwnd = cwnd* 2。

   但是，为了防止拥塞窗口增长过大而引起网络拥塞，另外设置了一个慢开始门限 ssthresh。

   ① 当 cwnd < ssthresh 时，使用上述的慢开始算法；

   ② 当 cwnd > ssthresh 时，停止使用慢开始，转而使用拥塞避免算法；

   ③ 当 cwnd == ssthresh 时，两者均可。

2. 拥塞避免

   拥塞控制是为了让拥塞窗口 cwnd 缓慢地增大，即**每经过一个往返时间 RTT （往返时间定义为发送方发送数据到收到确认报文所经历的时间）就把发送方的 cwnd 值加 1**，通过让 cwnd 线性增长，防止很快就遇到网络拥塞状态。

   **当网络拥塞发生时，让新的慢开始门限值变为发生拥塞时候的值的一半，并将拥塞窗口置为 1** ，然后再次重复两种算法（慢开始和拥塞避免），这时一瞬间会将网络中的数据量大量降低。

3. 快重传

   快重传算法要求**接收方每收到一个失序的报文就立即发送重复确认，而不要等到自己发送数据时才捎带进行确认**，假定发送方发送了 Msg 1 ~ Msg 4 这 4 个报文，已知接收方收到了 Msg 1，Msg 3 和 Msg 4 报文，此时因为接收到收到了失序的数据包，按照快重传的约定，接收方应立即向发送方发送 Msg 1 的重复确认。 于是在接收方收到 Msg 4 报文的时候，向发送方发送的仍然是 Msg 1 的重复确认。这样，发送方就收到了 3 次 Msg 1 的重复确认，于是立即重传对方未收到的 Msg 报文。**由于发送方尽早重传未被确认的报文段，因此，快重传算法可以提高网络的吞吐量**。

4. 快恢复

   快恢复算法是和快重传算法配合使用的，该算法主要有以下两个要点：

   - 当发送方连续收到三个重复确认，执行乘法减小，慢开始门限 ssthresh 值减半；

   - 由于发送方可能认为网络现在没有拥塞，因此与慢开始不同，把 cwnd 值设置为 ssthresh 减半之后的值，然后执行拥塞避免算法，线性增大 cwnd。

### TCP 粘包问题

为什么会发生TCP粘包和拆包?

1. **发送方写入的数据大于套接字缓冲区的大小**，此时将发生拆包。
2. 发送方写入的数据小于套接字缓冲区大小，由于 TCP 默认使用 Nagle 算法，只有当收到一个确认后，才将分组发送给对端，当**发送方收集了多个较小的分组，就会一起发送给对端**，这将会发生粘包。
3. 进行 MSS （最大报文长度）大小的 TCP 分段，**当 TCP 报文的数据部分大于 MSS 的时候将发生拆包**。
4. 发送方发送的数据太快，**接收方处理数据的速度赶不上发送端的速度**，将发生粘包。

常见解决方法

1. **在消息的头部添加消息长度字段**，服务端获取消息头的时候解析消息长度，然后向后读取相应长度的内容。
2. **固定消息数据的长度**，服务端每次读取既定长度的内容作为一条完整消息，当消息不够长时，空位补上固定字符。但是该方法会**浪费网络资源**。
3. 设置消息边界，也可以理解为分隔符，**服务端从数据流中按消息边界分离出消息内容**，一般使用换行符。

什么时候需要处理粘包问题？

当**接收端同时收到多个分组，并且这些分组之间毫无关系时，需要处理粘包**；而当多个分组属于同一数据的不同部分时，并不需要处理粘包问题。

### TCP 报文

<img src="https://pic.leetcode-cn.com/1612460289-ImAroH-TCP%E6%8A%A5%E6%96%87%E6%A0%BC%E5%BC%8F.png" alt="TCP报文格式.png" style="zoom: 33%;" />

**源端口和目的端口号：**它用于多路复用/分解来自或送往上层应用的数据，其和 IP 数据报中的源 IP 与目的 IP 地址一同确定一条 TCP 连接。

**序号和确认号字段：**序号是本报文段发送的数据部分中第一个字节的编号，在 TCP 传送的流中，每一个字节一个序号。例如一个报文段的序号为 100，此报文段数据部分共有 100 个字节，则下一个报文段的序号为 200。序号确保了 TCP 传输的有序性。确认号，即 ACK，指明下一个想要收到的字节序号，发送 ACK 时表明当前序号之前的所有数据已经正确接收。这两个字段的主要目的是保证数据可靠传输。

**首部长度：**该字段指示了以 32 比特的字为单位的 TCP 的首部长度。其中固定字段长度为 20 字节，由于首部长度可能含有可选项内容，因此 TCP 报头的长度是不确定的，20 字节是 TCP 首部的最小长度。

**保留：**为将来用于新的用途而保留。

**控制位：**URG 表示紧急指针标志，该位为 1 时表示紧急指针有效，为 0 则忽略；ACK 为确认序号标志，即相应报文段包括一个对已被成功接收报文段的确认；PSH 为 push 标志，当该位为 1 时，则指示接收方在接收到该报文段以后，应尽快将这个报文段交给应用程序，而不是在缓冲区排队； RST 为重置连接标志，当出现错误连接时，使用此标志来拒绝非法的请求；SYN 为同步序号，在连接的建立过程中使用，例如三次握手时，发送方发送 SYN 包表示请求建立连接；FIN 为 finish 标志，用于释放连接，为 1 时表示发送方已经没有数据发送了，即关闭本方数据流。

**接收窗口：**主要用于 TCP 流量控制。该字段用来告诉发送方其窗口（缓冲区）大小，以此控制发送速率，从而达到流量控制的目的。

**校验和：**奇偶校验，此校验和是对整个 TCP 报文段，包括 TCP 头部和数据部分。该校验和是一个端到端的校验和，由发送端计算和存储，并由接收端进行验证，主要目的是检验数据是否发生改动，若检测出差错，接收方会丢弃该 TCP 报文。

**紧急数据指针：**紧急数据用于告知紧急数据所在的位置，在URG标志位为 1 时才有效。当紧急数据存在时，TCP 必须通知接收方的上层实体，接收方会对紧急模式采取相应的处理。

**选项：**该字段一般为空，可根据首部长度进行推算。主要有以下作用：

① TCP 连接初始化时，通信双方确认最大报文长度。

② 在高速数据传输时，可使用该选项协商窗口扩大因子。

③ 作为时间戳时，提供一个 较为精准的 RTT，主要为了更好的实现 TCP 流量控制协议。

**数据：**TCP 报文中的数据部分也是可选的，例如==在 TCP 三次握手和四次挥手过程中，通信双方交换的报文只包含头部信息，数据部分为空，只有当连接成功建立后，TCP 包才真正携带数据==。

### 为什么服务端容易受到 SYN 攻击

在 TCP 建立连接的过程中，因为服务端不确定自己发给客户端的 SYN-ACK 消息或客户端反馈的 ACK 消息是否会丢在半路，所以会给每个待完成的半开连接状态设一个定时器，如果超过时间还没有收到客户端的 ACK 消息，则重新发送一次 SYN-ACK 消息给客户端，直到**重试超过一定次数时才会放弃**。

**服务端为了维持半开连接状态，需要分配内核资源维护半开连接**。当攻击者伪造海量的虚假 IP 向服务端发送 SYN 包时，就形成了 SYN FLOOD 攻击。攻击者故意不响应 ACK 消息，导致服务端被大量注定不能完成的半开连接占据，直到资源耗尽，停止响应正常的连接请求。

## UDP 模型

**UDP 只有一个 socket 接收缓冲区，没有 socket 发送缓冲区，即只要有数据就发，不管对方是否可以正确接收**。而在对方的 socket 接收缓冲区满了之后，**新来的数据报无法进入到 socket 接受缓冲区，此数据报就会被丢弃**，因此 UDP 不能保证数据能够到达目的地，此外，UDP 也没有流量控制和重传机制，故 UDP 的数据传输是不可靠的。

和 TCP 建立连接时采用三次握手不同，**UDP 中调用 connect 只是把对端的 IP 和端口号记录下来，并且 UDP 可多次调用 connect 来指定一个新的 IP 和端口号，或者断开旧的 IP 和端口号**（通过设置 connect 函数的第二个参数）。和普通的 UDP 相比，调用 connect 的 UDP 会提升效率，并且在高并发服务中会增加系统稳定性。

当 UDP 的发送端调用 bind 函数时，就会将这个套接字**指定一个端口**，若不调用 bind 函数，系统内核会随机分配一个端口给该套接字。**当手动绑定时，能够避免内核来执行这一操作，从而在一定程度上提高性能**。

## UDP 可靠化

## TCP 和 UDP 的区别及各自的适用场景

| 类型 | 是否面向连接 | 传输可靠性 | 传输形式   | 传输效率 | 所需资源 | 应用场景           | 首部字节 |
| ---- | ------------ | ---------- | ---------- | -------- | -------- | ------------------ | -------- |
| TCP  | 是           | 可靠       | 字节流     | 慢       | 多       | 文件传输、邮件传输 | 20~60    |
| UDP  | 否           | 不可靠     | 数据报文段 | 快       | 少       | 即时通讯、域名转换 | 8个字节  |

## HTTP 和 HTTPS

### HTTP 的工作方式

HTTP（Hyper Text Transfer Protocol: 超文本传输协议）是一种简单的请求 - 响应协议，被用于在 Web 浏览器和网站服务器之间传递消息。HTTP 使用 TCP（而不是 UDP）作为它的支撑运输层协议。==其默认工作在 TCP 协议 80 端口==，HTTP 客户机发起一个与服务器的 TCP 连接，一旦连接建立，浏览器和服务器进程就可以通过套接字接口访问 TCP。客户机从套接字接口发送 HTTP 请求报文和接收 HTTP 响应报文。类似地，服务器也是从套接字接口接收 HTTP 请求报文和发送 HTTP 响应报文。**其通信内容以明文的方式发送，不通过任何方式的数据加密**。当通信结束时，客户端与服务器关闭连接。

### HTTPS 的工作方式

HTTPS（Hyper Text Transfer Protocol over Secure Socket Layer）是以安全为目标的 HTTP 协议，**在 HTTP 的基础上通过传输加密和身份认证的方式保证了传输过程的安全性**。其工作流程如下：

1. 客户端发起一个 HTTPS 请求，并连接到服务器的 443 端口，==发送的信息主要包括自身所支持的算法列表和密钥长度等==；

2. 服务端将自身所支持的所有加密算法与客户端的算法列表进行对比并==选择一种支持的加密算法，然后将它和其它密钥组件一同发送给客户端==。

3. 服务器向客户端发送一个==包含数字证书的报文==，该数字证书中包含==证书的颁发机构、过期时间、服务端的公钥等信息==。

4. 最后服务端发送一个完成报文通知客户端 SSL 的第一阶段已经协商完成。

5. SSL 第一次协商完成后，客户端发送一个回应报文，报文中包含一个客户端生成的随机密码串，称为 pre_master_secre，并且该报文是经过证书中的公钥加密过的。

6. 紧接着客户端会发送一个报文提示服务端在此之后的报文是采用 pre_master_secre 加密的。

7. 客户端向服务端发送一个 finish 报文，这次握手中包含第一次握手至今所有报文的整体校验值，最终协商是否完成取决于服务端能否成功解密。

8. 服务端同样发送与第 6 步中相同作用的报文，已让客户端进行确认，最后发送 finish 报文告诉客户端自己能够正确解密报文。

当服务端和客户端的 finish 报文交换完成之后，SSL 连接就算建立完成了，之后就进行和 HTTP 相同的通信过程，**唯一不同的是在 HTTP 通信过程中并不是采用明文传输，而是采用对称加密的方式，其中对称密钥已经在 SSL 的建立过程中协商好了**。

### HTTP 和 HTTPS 的区别

- HTTP 协议以明文方式发送内容，**数据都是未加密的**，安全性较差。HTTPS **数据传输过程是加密的**，安全性较好。
- HTTP 和 HTTPS 使用的是完全不同的连接方式，用的端口也不一样，**前者是 80 端口，后者是 443 端口**。
- HTTPS 协议需要到**数字认证机构**（Certificate Authority, CA）申请证书，一般需要一定的费用。
- HTTP 页面响应比 HTTPS 快，主要因为 **HTTP 使用 3 次握手建立连接**，客户端和服务器需要握手 3 次，而 **HTTPS 除了 TCP 的 3 次握手，还需要经历一个 SSL 协商过程**。

### HTTPS 的加密方式

HTTPS 采用**对称加密和非对称加密相结合**的方式，首先使用 SSL/TLS 协议进行加密传输，为了弥补非对称加密的缺点，HTTPS 采用证书来进一步加强非对称加密的安全性，**通过非对称加密，客户端和服务端协商好之后进行通信传输的对称密钥，后续的所有信息都通过该对称秘钥进行加密解密**，完成整个 HTTPS 的流程。

## HTTP 协议

### HTTP 头部信息

HTTP 头部本质上是一个传递额外重要信息的键值对。主要分为：**通用头部，请求头部，响应头部和实体头部**。

通用头部：

| 协议头  | 说明                                           | 举例                                                         |
| ------- | ---------------------------------------------- | ------------------------------------------------------------ |
| Date    | 报文创建时间                                   | Date: Dec, 26 Dec 2015 17: 30: 00 GMT                        |
| Upgrade | 要求服务器升级到一个高版本协议                 | Upgrade: HTTP/2.0, SHTTP/1.3, IRC/6.9, RTA/x11               |
| Via     | 告诉服务器，这个请求是由哪些代理发出的         | Via: 1.0 fred, 1.1 [itbilu.com.com](http://itbilu.com.com/) (Apache/1.1) |
| Warning | 一个一般性的警告，表示在实体内容中可能存在错误 | Warning: 199 Miscellaneous warning                           |

请求头部：

| 协议头     | 说明                                     | 举例                                              |
| ---------- | ---------------------------------------- | ------------------------------------------------- |
| Accept     | 告诉服务器自己允许哪些媒体类型           | Accept: text/plain                                |
| Expect     | 表示客户端要求服务器做出特定的行为       | Expect: 100-continue                              |
| Host       | 表示服务器的域名以及服务器所监听的端口号 | Host: [www.itbilu.com:80](http://www.itbilu.com/) |
| User-Agent | 浏览器的身份标识字符串                   | User-Agent: Mozilla/……                            |

响应头部：

| 协议头   | 说明                 | 举例                                            |
| -------- | -------------------- | ----------------------------------------------- |
| Age      | 创建响应的时间       | Age：5744337                                    |
| Location | 表示重定向后的 URL   | Location: http://www.zcmhi.com/archives/94.html |
| Server   | 告知客户端服务器信息 | Server: Apache/1.3.27 (Unix) (Red-Hat/Linux)    |

实体头部：

| 协议头           | 说明                                          | 举例                                  |
| ---------------- | --------------------------------------------- | ------------------------------------- |
| Allow            | 对某网络资源的有效的请求行为，不允许则返回405 | Allow: GET, HEAD                      |
| Content-encoding | 返回内容的编码方式                            | Content-Encoding: gzip                |
| Content-MD5      | 返回资源的MD5校验值                           | Content-MD5: Q2hlY2sgSW50ZWdyaXR5IQ== |

### Keep-Alive 和非 Keep-Alive 区别

在早期的 HTTP/1.0 中，浏览器每次发起 HTTP 请求都要与服务器创建一个新的 TCP 连接，服务器完成请求处理后立即断开 TCP 连接，服务器不跟踪每个客户也不记录过去的请求。然而创建和关闭连接的过程需要消耗资源和时间，为了减少资源消耗，缩短响应时间，就需要重用连接。==在 HTTP/1.1 版本中默认使用持久连接，在此之前的 HTTP 版本的默认连接都是使用非持久连接==，**如果想要在旧版本的 HTTP 协议上维持持久连接，则需要指定 connection 的首部字段的值为 Keep-Alive 来告诉对方这个请求响应完成后不要关闭，下一次咱们还用这个请求继续交流**，我们用一个示意图来更加生动的表示两者的区别：

<img src="https://pic.leetcode-cn.com/1612195694-ROTKiX-%E9%95%BF%E8%BF%9E%E6%8E%A5%E5%92%8C%E7%9F%AD%E8%BF%9E%E6%8E%A5.png" alt="长连接和短连接.png" style="zoom:50%;" />

对于非 Keep-Alive 来说，必须为每一个请求的对象建立和维护一个全新的连接。**对于每一个这样的连接，客户机和服务器都要分配 TCP 的缓冲区和变量，这给服务器带来的严重的负担**，因为一台 Web 服务器可能同时服务于数以百计的客户机请求。在 Keep-Alive 方式下，服务器在响应后保持该 TCP 连接打开，在同一个客户机与服务器之间的后续请求和响应报文可通过相同的连接进行传送。甚至位于同一台服务器的多个 Web 页面在从该服务器发送给同一个客户机时，可以在单个持久 TCP 连接上进行。

然而，Keep-Alive 并不是没有缺点的，**当长时间的保持 TCP 连接时容易导致系统资源被无效占用**，若对 Keep-Alive 模式配置不当，将有可能比非 Keep-Alive 模式带来的损失更大。因此，**我们需要正确地设置 keep-alive timeout 参数，当 TCP 连接在传送完最后一个 HTTP 响应，该连接会保持 keepalive_timeout 秒，之后就开始关闭这个链接**。

### HTTP 长连接和短连接

**长连接：**多用于操作频繁，点对点的通讯，而且客户端连接数目较少的情况。例如即时通讯、网络游戏等。

**短连接：**用户数目较多的Web网站的 HTTP 服务一般用短连接。例如京东，淘宝这样的大型网站一般客户端数量达到千万级甚至上亿，若采用长连接势必会使得服务端大量的资源被无效占用，所以一般使用的是短连接。

### 获取 HTTP 报文的长度

当响应消息中存在 Content-Length 字段时，我们可以直接根据这个值来判断数据是否接收完成，==例如客户端向服务器请求一个静态页面或者一张图片时，服务器能够很清楚的知道请求内容的大小，因此可以通过消息首部字段 Content- Length 来告诉客户端需要接收多少数据==，但是如果服务器预先不知道请求内容的大小，例如加载动态页面的时候，就需要使用 Transfer-Encoding: chunked 的方式来代替 Content-Length。

**分块传输编码（Chunked transfer encoding）**是 HTTP/1.1 中引入的一种数据传输机制，其**允许 HTTP 由服务器发送给客户端的数据可以分成多个部分**，当数据分解成一系列数据块发送时，服务器就可以发送数据而不需要预先知道发送内容的总大小，每一个分块包含十六进制的长度值和数据，==最后一个分块长度值为0，表示实体结束，客户机可以以此为标志确认数据已经接收完毕==。

### HTTP 方法

HTTP/1.0 定义了三种请求方法：GET, POST 和 HEAD 方法。

HTTP/1.1 增加了六种请求方法：OPTIONS, PUT, PATCH, DELETE, TRACE 和 CONNECT 方法。

| 方法    | 描述                                                         |
| ------- | ------------------------------------------------------------ |
| GET     | 请求指定的页面信息，并返回具体内容，通常只用于读取数据。     |
| HEAD    | 类似于 GET 请求，只不过返回的响应中没有具体的内容，用于获取报头。 |
| POST    | 向指定资源提交数据进行处理请求（例如提交表单或者上传文件）。数据被包含在请求体中。POST 请求可能会导致新的资源的建立或已有资源的更改。 |
| PUT     | 替换指定的资源，没有的话就新增。                             |
| DELETE  | 请求服务器删除 URL 标识的资源数据。                          |
| CONNECT | 将服务器作为代理，让服务器代替用户进行访问。                 |
| OPTIONS | 向服务器发送该方法，会返回对指定资源所支持的 HTTP 请求方法。 |
| TRACE   | 回显服务器收到的请求数据，即服务器返回自己收到的数据，主要用于测试和诊断。 |
| PATCH   | 是对 PUT 方法的补充，用来对已知资源进行局部更新。            |

### GET 和 POST 的区别

- get 提交的数据会放在 URL 之后，并且**请求参数会被完整的保留在浏览器的记录里**，由于参数直接暴露在 URL 中，可能会存在安全问题，因此往往用于获取资源信息。而 post 参数放在请求主体中，并且**参数不会被保留**，相比 get 方法，post 方法更安全，主要用于修改服务器上的资源。
- get 请求**只支持 URL 编码**，post 请求**支持多种编码格式**。
- get **只支持 ASCII 字符格式的参数**，而 post 方法**没有限制**。
- get **提交的数据大小有限制**（这里所说的限制是针对浏览器而言的），而 post 方法**提交的数据没限制**
- get 方式需要使用 **Request.QueryString** 来取得变量的值，而 post 方式通过 **Request.Form** 来获取。
- get 方法**产生一个 TCP 数据包**，post 方法**产生两个**（并不是所有的浏览器中都产生两个）。

### HTTP 如何保存用户状态

我们知道，假如某个特定的客户机在短时间内两次请求同一个对象，服务器并不会因为刚刚为该用户提供了该对象就不再做出反应，而是重新发送该对象，就像该服务器已经完全忘记不久之前所做过的是一样。因为一个 **HTTP 服务器并不保存关于客户机的任何信息**，所以我们说 **HTTP 是一个无状态协议**。

通常有两种解决方案：

1. **基于 Session 实现的会话保持**

   在客户端第一次向服务器发送 HTTP 请求后，**服务器会创建一个 Session 对象并将客户端的身份信息以键值对的形式存储下来**，然后分配一个会话标识（SessionId）给客户端，这个会话标识一般保存在客户端 Cookie 中，**之后每次该浏览器发送 HTTP 请求都会带上 Cookie 中的 SessionId 到服务器**，服务器根据会话标识就可以将之前的状态信息与会话联系起来，从而实现会话保持。

   优点：**安全性高**，因为状态信息保存在服务器端。

   缺点：由于大型网站往往采用的是分布式服务器，浏览器发送的 HTTP 请求一般要先通过负载均衡器才能到达具体的后台服务器，倘若**同一个浏览器两次 HTTP 请求分别落在不同的服务器上时，基于 Session 的方法就不能实现会话保持了**。

   【解决方法：采用中间件，例如 Redis，我们通过**将 Session 的信息存储在 Redis 中**，使得每个服务器都可以访问到之前的状态信息】

2. **基于 Cookie 实现的会话保持**

   当服务器发送响应消息时，在 HTTP 响应头中设置 Set-Cookie 字段，用来存储客户端的状态信息。客户端解析出 HTTP 响应头中的字段信息，并根据其生命周期创建不同的 Cookie，这样一来每次浏览器发送 HTTP 请求的时候都会带上 Cookie 字段，从而实现状态保持。基于 Cookie 的会话保持与基于 Session 实现的会话保持最主要的区别是**前者完全将会话状态信息存储在浏览器 Cookie 中**。

   优点：服务器不用保存状态信息， **减轻服务器存储压力**，同时便于服务端做水平拓展。

   缺点：该方式不够安全，因为状态信息存储在客户端，这意味着不能在会话中保存机密数据。除此之外，浏览器每次发起 HTTP 请求时都需要发送额外的 Cookie 到服务器端，会**占用更多带宽**。

### HTTP 状态码

| 分类 | 分类描述                                                     |
| ---- | ------------------------------------------------------------ |
| 1XX  | 指示信息--表示请求正在处理                                   |
| 2XX  | 成功--表示请求已被成功处理完毕                               |
| 3XX  | 重定向--要完成的请求需要进行附加操作                         |
| 4XX  | 客户端错误--请求有语法错误或者请求无法实现，服务器无法处理请求 |
| 5XX  | 服务器端错误--服务器处理请求出现错误                         |

常见的状态码

| 状态码 | 英文名称                      | 中文描述                                                     |
| ------ | ----------------------------- | ------------------------------------------------------------ |
| 300    | Multiple Choices              | 多种选择。被请求的资源有一系列可供选择的回馈信息，用户或浏览器能够自行选择一个首选地址进行重定向 |
| 301    | Moved Permanently             | 永久移动。请求的资源已被永久地移动到新 URI，返回信息会包含新的 URI，浏览器会自动定向到新 URI |
| 302    | Found                         | 临时移动。与 301 类似。但资源只是临时被移动，客户端应继续使用原有URI |
| 304    | Not Modified                  | 未修改。如果客户端发送了一个带条件的 GET 请求且该请求已被允许，而文档的内容（自上次访问以来或者根据请求的条件）并没有改变，则服务器应当返回这个状态码 |
| 305    | Use Proxy                     | 使用代理。被请求的资源必须通过指定的代理才能被访问           |
| 307    | Temporary Redirect            | 临时重定向。请求的资源现在临时从不同的 URI 响应请求，与302类似 |
| 400    | Bad Request                   | 客户端请求的语法错误，服务器无法理解；请求的参数有误         |
| 401    | Unauthorized                  | 当前请求需要用户验证                                         |
| 403    | Forbidden                     | 服务器已经理解请求，但是拒绝执行它                           |
| 404    | Not Found                     | 请求失败，请求所希望得到的资源未被在服务器上发现             |
| 405    | Method Not Allowed            | 客户端请求中的方法被禁止                                     |
| 407    | Proxy Authentication Required | 与401响应类似，只不过客户端必须在代理服务器上进行身份验证    |
| 408    | Request Time-out              | 请求超时。服务器等待客户端发送的请求时间过长，超时           |
| 500    | Internal Server               | 服务器遇到了一个未曾预料的状况，导致了它无法完成对请求的处理 |
| 501    | Not Implemented               | 服务器不支持当前请求所需要的某个功能                         |
| 505    | HTTP Version not supported    | 服务器不支持，或者拒绝支持在请求中使用的 HTTP 版本           |

### HTTP/1.1 和 HTTP/1.0 的区别

主要区别如下：

- **缓存处理：**在 HTTP/1.0 中主要使用 header 里的 if-modified-Since, Expries 来做缓存判断的标准。而 HTTP/1.1 请求头中==添加了更多与缓存相关的字段，从而支持更为灵活的缓存策略==，例如 Entity-tag, If-Unmodified-Since, If-Match, If-None-Match 等可供选择的缓存头来控制缓存策略。

- **节约带宽：** 当客户端请求某个资源时，HTTP/1.0 ==默认将该资源相关的整个对象传送给请求方==，但很多时候可能客户端并不需要对象的所有信息。而在 HTTP/1.1 的请求头中引入了 range 头域，它==允许只请求部分资源==，其使得开发者可以多线程请求某一资源，从而充分的利用带宽资源，实现高效并发。

- **错误通知的管理：**HTTP/1.1 在 1.0 的基础上==新增了 24 个错误状态响应码==，例如 414 表示客户端请求中所包含的 URL 地址太长，以至于服务器无法处理；410 表示所请求的资源已经被永久删除。

- **Host 请求头：**早期 HTTP/1.0 中认为每台服务器都绑定一个唯一的 IP 地址并提供单一的服务，请求消息中的 URL 并没有传递主机名。而随着虚拟主机的出现，一台物理服务器上可以存在多个虚拟主机，并且它们共享同一个 IP 地址。为了**支持虚拟主机**，HTTP/1.1 中添加了 host 请求头，请求消息和响应消息中应声明这个字段，若请求消息中缺少该字段时服务端会响应一个 404 错误状态码。

- **长连接：**HTTP/1.0 默认浏览器和服务器之间保持短暂连接，浏览器的每次请求都需要与服务器建立一个 TCP 连接，服务器完成后立即断开 TCP 连接。HTTP/1.1 默认使用的是**持久连接**，其支持在同一个 TCP 请求中传送多个 HTTP 请求和响应。此之前的 HTTP 版本的默认连接都是使用非持久连接，如果想要在旧版本的 HTTP 协议上维持持久连接，则需要指定 Connection 的首部字段的值为 Keep-Alive。

### HTTP/1.X 和 HTTP/2.0 的区别

- 相比于 HTTP/1.X 的**文本（字符串）传送**， HTTP/2.0 采用**二进制传送**。**客户端和服务器传输数据时把数据分成帧，帧组成了数据流**，流具有流 ID 标识和优先级，通过优先级以及流依赖能够一定程度上解决关键请求被阻塞的问题。
- HTTP/2.0 **支持多路复用**。因为流 ID 的存在， 通过同一个 HTTP 请求可以实现多个 HTTP 请求传输，客户端和服务器可以通过流 ID 来标识究竟是哪个流从而定位到是哪个 HTTP 请求。
- HTTP/2.0 **头部压缩**。HTTP/2.0 通过 gzip 和 compress 压缩头部然后再发送，同时**通信双方会维护一张头信息表，所有字段都记录在这张表中**，在每次 HTTP 传输时只需要**传头字段在表中的索引**即可，大大减小了重传次数和数据量。
- HTTP/2.0 **支持服务器推送**。 **服务器在客户端未经请求许可的情况下，可预先向客户端推送需要的内容**，客户端在退出服务时可通过发送复位相关的请求来取消服务端的推送。

### HTTP/3

## IP 地址和 MAC 地址

MAC 地址是数据链路层和物理层使用的地址，是写在网卡上的物理地址。MAC 地址用来定义网络设备的位置。
IP 地址是网络层和以上各层使用的地址，是一种逻辑地址。IP 地址用来区别网络上的计算机。

### 为什么有了 MAC 地址还需要 IP 地址

如果我们只使用 MAC 地址进行寻址的话，我们需要路由器记住每个 MAC 地址属于哪一个子网，不然每一次路由器收到数据包时都要满世界寻找目的 MAC 地址。而我们知道 MAC 地址的长度为 48 位，也就是说最多总共有 2 的 48 次方个 MAC 地址，这就意味着每个路由器需要 256 T 的内存，这显然是不现实的。

和 MAC 地址不同，IP 地址是和地域相关的，在一个子网中的设备，我们给其分配的 IP 地址前缀都是一样的，这样路由器就能根据 IP 地址的前缀知道这个设备属于哪个子网，剩下的寻址就交给子网内部实现，从而大大减少了路由器所需要的内存。

### 为什么有了 IP 地址还需要 MAC 地址

只有当设备连入网络时，才能根据他进入了哪个子网来为其分配 IP 地址，在设备还没有 IP 地址的时候或者在分配 IP 地址的过程中，我们需要 MAC 地址来区分不同的设备。

### 同一个局域网内的两个私网地址，经过转换后外面看到的一样吗？

当采用静态或者动态转换时，由于一个私网 IP 地址对应一个公网地址，因此经过转换之后的公网 IP 地址是不同的；而采用端口复用方式的话，在一个子网中的所有地址都采用一个公网地址，但是使用的端口是不同的。

## OSI 七层模型和 TCP/IP 四层模型

<img src="https://pic.leetcode-cn.com/1612150605-NindRH-image.png" alt="image.png" style="zoom:50%;" />

### OSI 七层模型

OSI 模型全称为**开放式通信系统互连参考模型**，是国际标准化组织 ( ISO ) 提出的一个试图使各种计算机在世界范围内互连为网络的标准框架。 OSI 将计算机网络体系结构划分为七层，每一层实现各自的功能和协议，并完成与相邻层的接口通信。OSI 的服务定义详细说明了各层所提供的服务。**某一层的服务就是该层及其下各层的一种能力，它通过接口提供给更高一层**。各层所提供的服务与这些服务是怎么实现的无关。

1. 应用层

   应用层位于 OSI 参考模型的第七层，其作用是**通过应用程序间的交互来完成特定的网络应用**。该层协议==定义了应用进程之间的交互规则，通过不同的应用层协议为不同的网络应用提供服务==。例如域名系统 DNS，支持万维网应用的 HTTP 协议，电子邮件系统采用的 SMTP 协议等。在应用层交互的数据单元我们称之为**报文**。

2. 表示层

   表示层的作用是**使通信的应用程序能够解释交换数据的含义**，其位于 OSI 参考模型的第六层，向上为应用层提供服务，向下接收来自会话层的服务。该层提供的服务主要包括**数据压缩，数据加密以及数据描述**。这使得应用程序不必担心在各台计算机中表示和存储的内部格式差异。

3. 会话层

   会话层就是**负责建立、管理和终止表示层实体之间的通信会话**。该层提供了数据交换的定界和同步功能，包括了建立检查点和恢复方案的方法。

4. 传输层

   传输层的主要任务是**为两台主机进程之间的通信提供服务**。==应用程序利用该服务传送应用层报文==。该服务并不针对某一特定的应用，多种应用可以使用同一个运输层服务。由于一台主机可同时运行多个线程，因此运输层有**复用和分用**的功能。所谓复用就是指**多个应用层进程可同时使用下面运输层的服务**，分用和复用相反，是**运输层把收到的信息分别交付上面应用层中的相应进程**。

5. 网络层

   两台计算机之间传送数据时其通信链路往往不止一条，所传输的信息甚至可能经过很多通信子网。网络层的主要任务就是**选择合适的网间路由和交换节点，确保数据按时成功传送**。在发送数据时，==网络层把运输层产生的报文或用户数据报封装成分组和包向下传输到数据链路层==。在网络层使用的协议是无连接的网际协议（Internet Protocol）和许多路由协议，因此我们通常把该层简单地称为 IP 层。

6. 数据链路层

   数据链路层通常也叫做链路层，在物理层和网络层之间。==两台主机之间的数据传输，总是在一段一段的链路上传送的==，这就需要使用专门的链路层协议。在两个相邻节点之间传送数据时，**数据链路层将网络层交下来的 IP 数据报组装成帧，在两个相邻节点间的链路上传送帧**。每一帧包括数据和必要的控制信息。==通过控制信息我们可以知道一个帧的起止比特位置==，此外，也能==使接收端检测出所收到的帧有无差错，如果发现差错，数据链路层能够简单的丢弃掉这个帧，以避免继续占用网络资源==。

7. 物理层

   作为 OSI 参考模型中最低的一层，物理层的作用是**实现计算机节点之间比特流的透明传送，尽可能屏蔽掉具体传输介质和物理设备的差异**。使其上面的数据链路层不必考虑网络的具体传输介质是什么。该层的主要任务是确定与传输媒体的接口的一些特性（机械特性、电气特性、功能特性，过程特性）。


### TCP/IP 四层模型

1. 应用层

   TCP/IP 模型**将 OSI 参考模型中的会话层、表示层和应用层的功能合并到一个应用层实现**，通过不同的应用层协议为不同的应用提供服务。例如：FTP、Telnet、DNS、SMTP 等。

2. 传输层

   该层对应于 OSI 参考模型的传输层，**为上层实体提供源端到对端主机的通信功能**。==传输层定义了两个主要协议：传输控制协议（TCP）和用户数据报协议（UDP）==。其中面向连接的 TCP 协议保证了数据的传输可靠性，面向无连接的 UDP 协议能够实现数据包简单、快速地传输。

3. 网络层

   网络层对应 OSI 参考模型的网络层，**主要负责相同或不同网络中计算机之间的通信**。在网络层，==IP 协议提供的是一个可靠、无连接的数据报传递服务==。该协议实现两个基本功能：**寻址和分段**。根据数据报报头中的目的地址将数据传送到目的地址，在这个过程中 IP 负责选择传送路线。除了 IP 协议外，该层另外两个主要协议是**互联网组管理协议（IGMP）**和**互联网控制报文协议（ICMP）**。

4. 数据链路层

   数据链路层的功能对应于 OSI 参考模型中的物理层和数据链路层，它负责**监视数据在主机和网络之间的交换**。事实上，TCP/IP 并未真正描述这一层的实现，而由参与互连的各网络使用自己的物理层和数据链路层协议，然后与 TCP/IP 的网络接入层进行连接，因此具体的实现方法将随着网络类型的不同而有所差异。


### TCP/IP 五层模型

五层体系的协议结构是综合了 OSI 和 TCP/IP 优点的一种协议，包括应用层、传输层、网络层、数据链路层和物理层。其中**应用层对应 OSI 的上三层，下四层和 OSI 相同**。==五层协议的体系结构只是为介绍网络原理而设计的，实际应用还是 TCP/IP 四层体系结构==。

### OSI 模型和 TCP/IP 模型异同比较

- 相同点
  1. OSI 参考模型与 TCP/IP 参考模型都采用了层次结构。
  2. 都能够提供面向连接和无连接两种通信服务机制。
- 不同点
  1. OSI 采用的七层模型； TCP/IP 是四层结构。
  2. TCP/IP 参考模型没有对网络接口层进行细分，只是一些概念性的描述； OSI 参考模型对服务和协议做了明确的区分。
  3. OSI 先有模型，后有协议规范，适合于描述各种网络；TCP/IP 是先有协议集然后建立模型，不适用于非 TCP/IP 网络。
  4. TCP/IP 一开始就提出面向连接和无连接服务，而 OSI 一开始只强调面向连接服务，直到很晚才开始制定无连接的服务标准。
  5. OSI 参考模型虽然被看好，但将网络划分为七层，实现起来较困难；相反，TCP/IP 参考模型虽然有许多不尽人意的地方，但作为一种简化的分层结构还是比较成功的。

### OSI 和 TCP/IP 协议之间的对应关系

<img src="https://ftp.bmp.ovh/imgs/2021/03/64adc3b12a60bb17.png" style="zoom: 67%;" />

### 为什么 TCP/IP 去除了表示层和会话层

OSI 参考模型在提出时，他们的理想是非常好的，但实际上，**由于会话层、表示层、应用层都是在应用程序内部实现的，最终产出的是一个应用数据包，而应用程序之间是几乎无法实现代码的抽象共享的，这也就造成 OSI 设想中的应用程序维度的分层是无法实现的**，例如，我们几乎不会认为数据的压缩、加密算法算是一种协议，而会话的概念则更为抽象，难以用协议来进行描述，所以在后来的 TCP/IP 协议框架的设计中，便将表示层和会话层与应用层整合在一起，让整个过程更为清晰明了。

### 数据如何在各层之间传输

在发送主机端，一个应用层报文被传送到运输层。在最简单的情况下：

1. **运输层收取到报文并附上附加信息，该首部将被接收端的运输层使用**。应用层报文和运输层首部信息一道构成了运输层报文段。附加的信息可能包括：允许接收端运输层向上向适当的应用程序交付报文的信息以及差错检测位信息。该信息让接收端能够判断报文中的比特是否在途中已被改变。
2. 运输层则向网络层传递该报文段，**网络层增加了如源和目的端系统地址等网络层首部信息，生成了网络层数据报**，该数据报接下来被传递给链路层。
3. 在数据链路层数据包**添加发送端 MAC 地址和接收端 MAC 地址后被封装成数据帧，在物理层数据帧被封装成比特流，之后通过传输介质传送到对端**。

### TCP/IP 的数据链路层交互过程

网络层等到数据链路层用 MAC 地址作为通信目标，数据包到达网络层准备往数据链路层发送的时候，首先会去自己的ARP 缓存表（存着 IP - MAC 对应关系）去查找改目标 IP 的 MAC 地址，如果查到了，就讲目标 IP 的 MAC 地址封装到链路层数据包的包头。如果缓存中没有找到，会发起一个广播：who is ip XXX tell ip XXX，所有收到的广播的机器看这个 IP 是不是自己的，如果是自己的，则以单拨的形式将自己的 MAC 地址回复给请求的机器。

### 传递到 IP 层怎么知道报文该给哪个应用程序，怎么区分 UDP 报文还是 TCP 报文

看 IP 头的标识。

## 网络编程的具体步骤

<img src="https://uploadfiles.nowcoder.com/images/20190315/308571_1552654678444_69CF8398BCC9F204991E623723D022E7" alt="img" style="zoom: 67%;" />

<img src="https://uploadfiles.nowcoder.com/images/20190315/308571_1552654687053_263E6AFD1A48F8511D04B67EB12AA24C" alt="img" style="zoom:67%;" />

- send 函数用来向 TCP 连接的另一端发送数据。客户程序一般用 send 函数向服务器发送请求，而服务器则通常用send 函数来向客户程序发送应答，send 的作用是将要发送的数据拷贝到缓冲区，协议负责传输。

- recv 函数用来从 TCP 连接的另一端接收数据，当应用程序调用 recv 函数时，recv 先等待 s 的发送缓冲中的数据被协议传送完毕，然后从缓冲区中读取接收到的内容给应用层。

- accept 函数用了接收一个连接，内核维护了半连接队列和一个已完成连接队列，当队列为空的时候，accept 函数阻塞，不为空的时候 accept 函数从上边取下来一个已完成连接，返回一个文件描述符。

## server端监听端口，但还没有客户端连接进来，此时进程处于什么状态

看具体的服务端编程实现。

## 数字证书

数字证书在一个身份和该身份的持有者所拥有的公/私钥对之间建立了一种联系，由认证中心（CA）或者认证中心的下级认证中心颁发的。根证书是认证中心与用户建立信任关系的基础。在用户使用数字证书之前必须首先下载和安装。

认证中心是一家能向用户签发数字证书以确认用户身份的管理机构。为了防止数字凭证的伪造，认证中心的公共密钥必须是可靠的，认证中心必须公布其公共密钥或由更高级别的认证中心提供一个电子凭证来证明其公共密钥的有效性，后一种方法导致了多级别认证中心的出现。

数字证书颁发过程如下：用户产生了自己的密钥对，并将公共密钥及部分个人身份信息传送给一家认证中心。认证中心在核实身份后，将执行一些必要的步骤，以确信请求确实由用户发送而来，然后，认证中心将发给用户一个数字证书，该证书内附了用户和他的密钥等信息，同时还附有对认证中心公共密钥加以确认的数字证书。当用户想证明其公开密钥的合法性时，就可以提供这一数字证书。

## DNS 的作用和原理

### DNS

DNS（Domain Name System）是域名系统的英文缩写，**是一种组织成域层次结构的计算机和网络服务命名系统，用于 TCP/IP 网络**。

### DNS 的作用

通常我们有两种方式识别主机：通过主机名或者 IP 地址。人们喜欢便于记忆的主机名表示，而路由器则喜欢定长的、有着层次结构的 IP 地址。为了满足这些不同的偏好，我们就需要一种能够进行主机名到 IP 地址转换的目录服务，域名系统作为**将域名和 IP 地址相互映射**的一个**分布式数据库**，能够使人更方便地访问互联网。

#### DNS域名解析原理

DNS 采用了分布式的设计方案，其域名空间采用一种树形的层次结构：

<img src="https://pic.leetcode-cn.com/1612458680-mTSUQn-DNS%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84.png" alt="DNS服务器的层次结构.png" style="zoom:50%;" />

上图展示了 DNS 服务器的部分层次结构，从上到下依次为根域名服务器、顶级域名服务器和权威域名服务器。其实**根域名服务器**在因特网上有13个，大部分位于北美洲。第二层为**顶级域服务器**，这些服务器负责顶级域名（如 com、org、net、edu）和所有国家的顶级域名（如uk、fr、ca 和 jp）。在第三层为**权威 DNS 服务器**，因特网上具有公共可访问主机（例如 Web 服务器和邮件服务器）的每个组织机构必须提供公共可访问的 DNS 记录，这些记录由组织机构的权威 DNS 服务器负责保存，这些记录将这些主机的名称映射为 IP 地址。

除此之外，还有一类重要的 DNS 服务器，叫做**本地 DNS 服务器**。本地 DNS 服务器严格来说不在 DNS 服务器的层次结构中，但它对 DNS 层次结构是很重要的。一般来说，**每个网络服务提供商（ISP） 都有一台本地 DNS 服务器**。当主机与某个 ISP 相连时，该 ISP 提供一台主机的 IP 地址，该主机具有一台或多台其本地 DNS 服务器的 IP 地址。主机的本地 DNS 服务器通常和主机距离较近，当主机发起 DNS 请求时，该请求被发送到本地 DNS 服务器，它起着代理的作用，并将该请求转发到 DNS 服务器层次结构中。

我们以一个例子来了解 DNS 的工作原理，假设主机 A（IP 地址为 abc.xyz.edu） 想知道主机 B 的 IP 地址 （def.mn.edu），如下图所示，**主机 A 首先向它的本地 DNS 服务器发送一个 DNS 查询报文**。该查询报文含有被转换的主机名 def.mn.edu。**本地 DNS 服务器将该报文转发到根 DNS 服务器，根 DNS 服务器注意到查询的 IP 地址前缀为 edu 后向本地 DNS 服务器返回负责 edu 的顶级域名服务器的 IP 地址列表**。**该本地 DNS 服务器则再次向这些顶级域名服务器发送查询报文**。**该顶级域名服务器注意到 mn.edu 的前缀，并用权威域名服务器的 IP 地址进行响应**。通常情况下，==顶级域名服务器并不总是知道每台主机的权威 DNS 服务器的 IP 地址，而只知道中间的某个服务器，该中间 DNS 服务器依次能找到用于相应主机的 IP 地址==，我们假设中间经历了权威服务器 ① 和 ②，**最后找到了负责 def.mn.edu 的权威 DNS 服务器 ③，之后，本地 DNS 服务器直接向该服务器发送查询报文从而获得主机 B 的IP 地址**。

<img src="https://pic.leetcode-cn.com/1612458718-QcTlwM-DNS.png" alt="DNS.png" style="zoom: 33%;" />

在上图中，IP 地址的查询其实经历了两种查询方式，分别是递归查询和迭代查询。

> 拓展：域名解析查询的两种方式
>
> - **递归查询：**如果主机所询问的本地域名服务器不知道被查询域名的 IP 地址，那么本地域名服务器就以 DNS 客户端的身份，向其他根域名服务器继续发出查询请求报文，即替主机继续查询，而不是让主机自己进行下一步查询，如上图步骤（1）和（10）。
> - **迭代查询：**当根域名服务器收到本地域名服务器发出的迭代查询请求报文时，要么给出所要查询的 IP 地址，要么告诉本地服务器下一步应该找哪个域名服务器进行查询，然后让本地服务器进行后续的查询，如上图步骤（2）~（9）。
>

#### DNS为什么用UDP

更正确的答案是 **DNS 既使用 TCP 又使用 UDP**。

当进行**区域传送**（主域名服务器向辅助域名服务器传送变化的那部分数据）时会使用 TCP，因为**数据同步传送的数据量比一个请求和应答的数据量要多，而 TCP 允许的报文长度更长，因此为了保证数据的正确性，会使用基于可靠连接的 TCP**。

当**客户端向 DNS 服务器查询域名**（域名解析）的时候，**一般返回的内容不会超过 UDP 报文的最大长度**，即 512 字节。**用 UDP 传输时，不需要经过 TCP 三次握手的过程，从而大大提高了响应速度，但这要求域名解析器和域名服务器都必须自己处理超时和重传从而保证可靠性**。

#### DNS劫持

DNS 劫持即域名劫持，是通过将原域名对应的 IP 地址进行替换从而使得用户访问到错误的网站或者使得用户无法正常访问网站的一种攻击方式。域名劫持往往只能在特定的网络范围内进行，范围外的 DNS 服务器能够返回正常的 IP 地址。攻击者可以冒充原域名所属机构，通过电子邮件的方式修改组织机构的域名注册信息，或者将域名转让给其它组织，并将新的域名信息保存在所指定的 DNS 服务器中，从而使得用户无法通过对原域名进行解析来访问目的网址。

**具体实施步骤如下：**

1. 获取要劫持的域名信息：攻击者首先会**访问域名查询站点查询要劫持的域名信息**。

2. 控制域名相应的 E-MAIL 账号：在获取到域名信息后，攻击者通过暴力破解或者专门的方法**破解公司注册域名时使用的 E-mail 账号所对应的密码**。更高级的攻击者甚至能够直接对 E-mail 进行信息窃取。

3. 修改注册信息：当攻击者破解了 E-MAIL 后，会**利用相关的更改功能修改该域名的注册信息**，包括域名拥有者信息，DNS 服务器信息等。

4. 使用 E-MAIL 收发确认函：在修改完注册信息后，攻击者在 E-mail 真正拥有者之前**收到修改域名注册信息的相关确认信息，并回复确认修改文件**，待网络公司恢复已成功修改信件后，攻击者便成功完成 DNS 劫持。

**用户端的一些预防手段：**

- 直接通过 IP 地址访问网站，避开 DNS 劫持。
- 由于域名劫持往往只能在特定的网络范围内进行，因此一些高级用户可以通过网络设置让 DNS 指向正常的域名服务器以实现对目的网址的正常访问，例如将计算机首选 DNS 服务器的地址固定为 8.8.8.8。

## socket 套接字

套接字（Socket）是**对网络中不同主机上的应用进程之间进行双向通信的端点的抽象**，网络进程通信的一端就是一个套接字，**不同主机上的进程便是通过套接字发送报文来进行通信**。例如 TCP 用主机的 IP 地址 + 端口号作为 TCP 连接的端点，这个端点就叫做套接字。

套接字主要有以下三种类型：

- **流套接字**（SOCK_STREAM）：**流套接字基于 TCP 传输协议**，主要用于提供面向连接、可靠的数据传输服务。由于 TCP 协议的特点，使用流套接字进行通信时能够保证数据无差错、无重复传送，并按顺序接收，==通信双方不需要在程序中进行相应的处理==。
- **数据报套接字**（SOCK_DGRAM）：和流套接字不同，**数据报套接字基于 UDP 传输协议**，对应于无连接的 UDP 服务应用。该服务并不能保证数据传输的可靠性，也无法保证对端能够顺序接收到数据。此外，==通信两端不需建立长时间的连接关系==，当 UDP 客户端发送一个数据给服务器后，其可以通过同一个套接字给另一个服务器发送数据。**当用 UDP 套接字时，丢包等问题需要在程序中进行处理**。
- **原始套接字**（SOCK_RAW）：由于流套接字和数据报套接字只能读取 TCP 和 UDP 协议的数据，当需要**传送非传输层数据包**（例如 Ping 命令时用的 ICMP 协议数据包）或者遇到**操作系统无法处理的数据包**时，此时就需要建立原始套接字来发送。

## URL 和 URI

URL，即**统一资源定位符** (Uniform Resource Locator )，URL 其实就是我们平时上网时输入的网址，**它标识一个互联网资源，并指定对其进行操作或获取该资源的方法**。例如 https://leetcode-cn.com/problemset/all/ 这个 URL，标识一个特定资源并表示该资源的某种形式是可以通过 HTTP 协议从相应位置获得。

从定义即可看出，URL 是 URI 的一个子集，两者都定义了资源是什么，而 URL 还定义了如何能访问到该资源。URI 是一种语义上的抽象概念，可以是绝对的，也可以是相对的，而URL则必须提供足够的信息来定位，是绝对的。简单地说，**只要能唯一标识资源的就是 URI，在 URI 的基础上给出其资源的访问方式的就是 URL**。

## 访问网站慢怎么排查和解决

网页打开速度慢的原因有很多，这里列举出一些较常出现的问题：

1. 首先最直接的方法是**查看本地网络是否正常**，可以通过网络测速软件例如电脑管家等对电脑进行测速，若网速正常，我们**查看网络带宽是否被占用**，例如当你正在下载电影时并且没有限速，是会影响你打开网页的速度的，这种情况往往是处理器内存小导致的；

2. 当网速测试正常时，我们对网站服务器速度进行排查，**通过 ping 命令查看链接到服务器的时间和丢包等情况**，一个速度好的机房，首先丢包率不能超过 1%，其次 ping 值要小，最后是 ping 值要稳定，如最大和最小差值过大说明路由不稳定。或者我们也可以查看同台服务器上其他网站的打开速度，看是否其他网站打开也慢。

3. 如果网页打开的速度时快时慢，甚至有时候打不开，有可能是**空间不稳定**的原因。当确定是该问题时，就要找你的空间商解决或换空间商了，如果购买空间的话，可选择购买购买双线空间或多线空间；如果是在有的地方打开速度快，有的地方打开速度慢，那应该是**网络线路**的问题。电信线路用户访问放在联通服务器的网站，联通线路用户访问放在电信服务器上的网站，相对来说打开速度肯定是比较慢。

4. 从网站本身找原因。网站的问题主要包括网站程序设计、网页设计结构和网页内容三个部分。
   - 网站程序设计：当访问网页中有拖慢网站打开速度的代码，会影响网页的打开速度，例如网页中的统计代码，我们最好将其放在网站的末尾。因此我们需要查看网页程序的设计结构是否合理；
   - 网页设计结构：如果是 table 布局的网站，查看是否嵌套次数太多，或是一个大表格分成多个表格这样的网页布局，此时我们可以采用 div 布局并配合 css 进行优化。
   - 网页内容：查看网页中是否有许多尺寸大的图片或者尺寸大的 flash 存在，我们可以通过降低图片质量，减小图片尺寸，少用大型 flash 加以解决。此外，有的网页可能过多地引用了其他网站的内容，若某些被引用的网站访问速度慢，或者一些页面已经不存在了，打开的速度也会变慢。一种直接的解决方法是去除不必要的加载项。

## 应用层的其它协议

FTP（File Transfer Protocol，文件传输协议）是用于在网络上进行文件传输的一套标准协议，使用客户/服务器模式，使用 TCP 数据报，提供交互式访问，双向传输。

TFTP（Trivial File Transfer Protocol，简单文件传输协议）一个小且易实现的文件传输协议，也使用客户/服务器方式，使用 UDP 数据报，只支持文件传输而不支持交互，没有列目录，不能对用户进行身份鉴定。

SMTP（Simple Main Transfer Protocol，简单邮件传输协议）是在 Internet 传输 Email 的标准，是一个相对简单的基于文本的协议。在其之上指定了一条消息的一个或多个接收者（在大多数情况下被确认是存在的），然后消息文本会被传输。可以很简单地通过 Telnet 程序来测试一个 SMTP 服务器。SMTP 使用 TCP 端口 25。

DHCP ( Dynamic Host Configuration Protocol，动态主机设置协议 ) 是一个局域网的网络协议，使用 UDP 协议工作，主要有两个用途：

- 用于内部网络或网络服务供应商自动分配 IP 地址给用户
- 用于内部网络管理员作为对所有电脑作中央管理的手段

## 用户输入网址到显示对应页面的全过程

<img src="https://pic.leetcode-cn.com/1612459029-slhrTZ-%E9%A1%B5%E9%9D%A2%E6%98%BE%E7%A4%BA%E6%B5%81%E7%A8%8B%E5%9B%BE.png" alt="页面显示流程图.png" style="zoom:50%;" />

1. **DNS 解析：**当用户输入一个网址并按下回车键的时候，浏览器获得一个域名，而在实际通信过程中，我们需要的是一个 IP 地址，因此我们需要先把域名转换成相应 IP 地址。【具体细节看问题 18.3 】

2. **TCP 连接：**浏览器通过 DNS 获取到 Web 服务器真正的 IP 地址后，便向 Web 服务器发起 TCP 连接请求，通过 TCP 三次握手建立好连接后，浏览器便可以将 HTTP 请求数据发送给服务器了。【三次握手放在传输层详细讲解】

3. **发送 HTTP 请求：**浏览器向 Web 服务器发起一个 HTTP 请求，HTTP 协议是建立在 TCP 协议之上的应用层协议，其本质是在建立起的 TCP 连接中，按照 HTTP 协议标准发送一个索要网页的请求。在这一过程中，会涉及到负载均衡等操作。

> 拓展：什么是负载均衡？
>
> 负载均衡，英文名为 Load Balance，其含义是指将负载（工作任务）进行平衡、分摊到多个操作单元上进行运行，例如 FTP 服务器、Web 服务器、企业核心服务器和其他主要任务服务器等，从而协同完成工作任务。负载均衡建立在现有的网络之上，它提供了一种透明且廉价有效的方法扩展服务器和网络设备的带宽、增加吞吐量、加强网络处理能力并提高网络的灵活性和可用性。
>
> 负载均衡是分布式系统架构设计中必须考虑的因素之一，例如天猫、京东等大型用户网站中为了处理海量用户发起的请求，其往往采用分布式服务器，并通过引入反向代理等方式将用户请求均匀分发到每个服务器上，而这一过程所实现的就是负载均衡。
>

4. **处理请求并返回：**服务器获取到客户端的 HTTP 请求后，会根据 HTTP 请求中的内容来决定如何获取相应的文件，并将文件发送给浏览器。

5. **浏览器渲染：**浏览器根据响应开始显示页面，首先解析 HTML 文件构建 DOM 树，然后解析 CSS 文件构建渲染树，等到渲染树构建完成后，浏览器开始布局渲染树并将其绘制到屏幕上。

6. **断开连接：**客户端和服务器通过四次挥手终止 TCP 连接。【其中的细节放在传输层详细讲解】

## IP 协议

IP 协议（Internet Protocol）又称互联网协议，是支持网间互联的数据包协议。该协议工作在网络层，主要目的就是为了提高网络的可扩展性，和传输层 TCP 相比，**IP 协议提供一种无连接/不可靠、尽力而为的数据包传输服务**，其与 TCP 协议（传输控制协议）一起构成了 TCP/IP 协议族的核心。IP 协议主要有以下几个作用：

- **寻址和路由：**在 IP 数据包中会携带**源 IP 地址和目的 IP 地址**来标识该数据包的源主机和目的主机。IP 数据报在传输过程中，每个中间节点（IP 网关、路由器）只根据网络地址进行转发，如果中间节点是路由器，则路由器会根据路由表选择合适的路径。IP 协议根据**路由选择协议**提供的路由信息对 IP 数据报进行转发，直至抵达目的主机。
- **分段与重组：**IP 数据包在传输过程中可能会经过不同的网络，==在不同的网络中数据包的最大长度限制是不同的==，IP 协议通过**给每个 IP 数据包分配一个标识符以及分段与组装的相关信息**，使得数据包在不同的网络中能够传输，**被分段后的 IP 数据报可以独立地在网络中进行转发**，在到达目的主机后由**目的主机完成重组工作，恢复出原来的 IP 数据包**。

### IPv4 地址不够怎么办

- DHCP：**动态主机配置协议**。动态分配 IP 地址，只给接入网络的设备分配IP地址，因此同一个 MAC 地址的设备，每次接入互联网时，得到的IP地址不一定是相同的，该协议使得空闲的 IP 地址可以得到充分利用。
- CIDR：**无类别域间路由**。CIDR 消除了传统的 A 类、B 类、C 类地址以及划分子网的概念，因而更加有效的分配 IPv4 的地址空间，但无法从根本上解决地址耗尽问题。
- NAT：**网络地址转换协议**。我们知道属于不同局域网的主机可以使用相同的 IP 地址，从而一定程度上缓解了 IP 资源枯竭的问题。然而主机在局域网中使用的 IP 地址是不能在公网中使用的，当局域网主机想要与公网进行通信时， NAT 方法可以将该主机 IP 地址转换成全球 IP 地址。该协议能够有效解决 IP 地址不足的问题。
- **IPv6** ：作为接替 IPv4 的下一代互联网协议，其可以实现 2 的 128 次方个地址，而这个数量级，即使是给地球上每一颗沙子都分配一个IP地址，该协议能够从根本上解决 IPv4 地址不够用的问题。

### 路由器的分组转发流程

1. 从 IP 数据包中提取出目的主机的 IP 地址，找到其所在的网络；

2. 判断目的 IP 地址所在的网络是否与本路由器直接相连，如果是则不需要经过其它路由器直接交付，否则执行 ③；

3. 检查路由表中是否有目的 IP 地址的特定主机路由。如果有，则按照路由表传送到下一跳路由器中，否则执行 ④；

4. 逐条检查路由表，若找到匹配路由，则按照路由表转发到下一跳路由器中，否则执行步骤 ⑤；

5. 若路由表中设置有默认路由，则按照默认路由转发到默认路由器中，否则执行步骤 ⑥；

6. 无法找到合适路由，向源主机报错。

### 路由器和交换机的区别

- 交换机：交换机用于局域网，利用主机的物理地址（MAC 地址）确定数据转发的目的地址，它工作于数据链路层。
- 路由器：路由器通过数据包中的目的 IP 地址识别不同的网络从而确定数据转发的目的地址，网络号是唯一的。路由器根据路由选择协议和路由表信息从而确定数据的转发路径，直到到达目的网络，它工作于网络层。

### ICMP 协议概念和作用

ICMP（Internet Control Message Protocol）是**因特网控制报文协议**，主要是实现 IP 协议中未实现的部分功能，是一种网络层协议。**该协议并不传输数据，只传输控制信息来辅助网络层通信**。其主要的功能是**验证网络是否畅通（确认接收方是否成功接收到 IP 数据包）以及辅助 IP 协议实现可靠传输（若发生 IP 丢包，ICMP 会通知发送方 IP 数据包被丢弃的原因，之后发送方会进行相应的处理）**。

### ICMP 的应用

- **Ping**（Packet Internet Groper），即因特网包探测器，是一种工作在网络层的服务命令，主要用于**测试网络连接量**。本地主机通过向目的主机发送 ICMP Echo 请求报文，目的主机收到之后会发送 Echo 响应报文，Ping 会根据时间和成功响应的次数估算出数据包往返时间以及丢包率从而推断网络是否通常、运行是否正常等。
- **TraceRoute** 是 ICMP 的另一个应用，其主要用来**跟踪一个分组从源点耗费最少 TTL 到达目的地的路径**。TraceRoute 通过逐渐增大 TTL 值并重复发送数据报来实现其功能，首先，TraceRoute 会发送一个 TTL 为 1 的 IP 数据报到目的地，当路径上的第一个路由器收到这个数据报时，它将 TTL 的值减 1，此时 TTL = 0，所以路由器会将这个数据报丢掉，并返回一个差错报告报文，之后源主机会接着发送一个 TTL 为 2 的数据报，并重复此过程，直到数据报能够刚好到达目的主机。此时 TTL = 0，因此目的主机要向源主机发送 ICMP 终点不可达差错报告报文，之后源主机便知道了到达目的主机所经过的路由器 IP 地址以及到达每个路由器的往返时间。

## ARP 地址解析协议

ARP（Address Resolution Protocol）是地址解析协议的缩写，该协议提供**根据 IP 地址获取物理地址**的功能，它工作在第二层，**是一个数据链路层协议**，其在本层和物理层进行联系，同时向上层提供服务。当通过以太网发送 IP 数据包时，需要先封装 32 位的 IP 地址和 48位 MAC 地址。在局域网中两台主机进行通信时需要依靠各自的物理地址进行标识，但由于发送方只知道目标 IP 地址，不知道其 MAC 地址，因此需要使用地址解析协议。 ARP 协议的解析过程如下：

1. 首先，每个主机都会在自己的 ARP 缓冲区中建立一个 ARP 列表，以表示 IP 地址和 MAC 地址之间的对应关系；

2. 当源主机要发送数据时，首先检查 ARP 列表中是否有 IP 地址对应的目的主机 MAC 地址，如果存在，则可以直接发送数据，否则就向同一子网的所有主机发送 ARP 数据包。该数据包包括的内容有源主机的 IP 地址和 MAC 地址，以及目的主机的 IP 地址。

3. 当本网络中的所有主机收到该 ARP 数据包时，首先检查数据包中的目的主机IP 地址是否是自己的 IP 地址，如果不是，则忽略该数据包，如果是，则首先从数据包中取出源主机的 IP 和 MAC 地址写入到 ARP 列表中，如果已经存在，则覆盖，然后将自己的 MAC 地址写入 ARP 响应包中，告诉源主机自己是它想要找的 MAC 地址。

4. 源主机收到 ARP 响应包后。将目的主机的 IP 和 MAC 地址写入 ARP 列表，并利用此信息发送数据。如果源主机一直没有收到 ARP 响应数据包，表示 ARP 查询失败。

## NAT 网络地址转换

NAT（Network Address Translation），即网络地址转换，它是一种**把内部私有网络地址翻译成公有网络 IP 地址**的技术。该技术不仅能解决 IP 地址不足的问题，而且还能隐藏和保护网络内部主机，从而避免来自外部网络的攻击。

NAT 的实现方式主要有三种：

- 静态转换：**内部私有 IP 地址和公有 IP 地址是一对一的关系，并且不会发生改变**。通过静态转换，可以实现外部网络对内部网络特定设备的访问，这种方式原理简单，但当某一共有 IP 地址被占用时，跟这个 IP 绑定的内部主机将无法访问 Internet。
- 动态转换：采用动态转换的方式时，**私有 IP 地址每次转化成的公有 IP 地址是不唯一的**。当私有 IP 地址被授权访问 Internet 时会被随机转换成一个合法的公有 IP 地址。当 ISP 通过的合法 IP 地址数量略少于网络内部计算机数量时，可以采用这种方式。
- 端口多路复用：该方式将外出数据包的源端口进行端口转换，通过**端口多路复用**的方式，实现**内部网络所有主机共享一个合法的外部 IP 地址进行 Internet 访问**，从而最大限度地节约 IP 地址资源。同时，该方案可以隐藏内部网络中的主机，从而有效避免来自 Internet 的攻击。

## 什么是 TTL

TTL 是指生存时间，简单来说，它表示了**数据包在网络中的时间**。**每经过一个路由器后 TTL 就减一**，这样 TTL 最终会减为 0 ，**当 TTL 为 0 时，则将数据包丢弃**。通过设置 TTL 可以**避免这两个路由器之间形成环导致数据包在环路上死转**的情况，由于有了 TTL ，当 TTL 为 0 时，数据包就会被抛弃。

## 以太网中的 CSMA/CD 协议

CSMA/CD 为载波侦听多路访问/冲突检测，是像以太网这种广播网络采用的一种机制，我们知道在以太网中多台主机在同一个信道中进行数据传输，CSMA/CD 很好的解决了共享信道通信中出现的问题，它的工作原理主要包括两个部分：

- **载波监听：**当使用 CSMA/CD 协议时，总线上的各个节点都在监听信道上是否有信号在传输，如果有的话，表明信道处于忙碌状态，继续保持监听，直到信道空闲为止。如果发现信道是空闲的，就立即发送数据。
- **冲突检测：**当两个或两个以上节点同时监听到信道空闲，便开始发送数据，此时就会发生碰撞（数据的传输延迟也可能引发碰撞）。当两个帧发生冲突时，数据帧就会破坏而失去了继续传输的意义。在数据的发送过程中，以太网是一直在监听信道的，当检测到当前信道冲突，就立即停止这次传输，避免造成网络资源浪费，同时向信道发送一个「冲突」信号，确保其它节点也发现该冲突。之后采用一种二进制退避策略让待发送数据的节点随机退避一段时间之后重新。

## 物理层主要做什么事情

作为 OSI 参考模型最低的一层，物理层是整个开放系统的基础，该层利用传输介质为通信的两端建立、管理和释放物理连接，**实现比特流的透明传输**。物理层考虑的是怎样才能在连接各种计算机的传输媒体上传输数据比特流，**其尽可能地屏蔽掉不同种类传输媒体和通信手段的差异，使物理层上面的数据链路层感觉不到这些差异**，这样就可以使数据链路层只考虑完成本层的协议和服务，而不必考虑网络的具体传输媒体和通信手段是什么。

## 主机间的通信方式

- 单工通信：也叫**单向通信**，发送方和接收方是固定的，消息只能单向传输。例如采集气象数据、家庭电费，网费等数据收集系统，或者打印机等应用主要采用单工通信。
- 半双工通信：也叫**双向交替通信**，通信双方都可以发送消息，但同一时刻同一信道只允许单方向发送数据。例如传统的对讲机使用的就是半双工通信。
- 全双工通信：也叫**双向同时通信**，全双工通信允许通信双方同时在两个方向是传输，其要求通信双方都具有独立的发送和接收数据的能力。例如平时我们打电话，自己说话的同时也能听到对面的声音。

## 对称加密和非对称加密

- 加密和解密的过程不同：对称加密和解密过程使用**同一个密钥**；非对称加密中加密和解密采用公钥和私钥两个密钥，一般**使用公钥进行加密，使用私钥进行解密**。
- 加密和解密的速度不同：**对称加密和解密速度较快**，当数据量比较大时适合使用；**非对称加密和解密时间较长**，速度相对较慢，适合少量数据传输的场景。
- 传输的安全性不同：采用对称加密方式进行通信时，**收发双方在数据传送前需要协定好密钥，而这个密钥还有可能被第三方窃听到的**，一旦密钥泄漏，之后的通信就完全暴漏给攻击者了；非对称加密采用公钥加密和私钥解密的方式，其中私钥是基于不同的算法生成的随机数，公钥可以通过私钥通过一定的算法推导得出，并且私钥到公钥的推导过程是不可逆的，也就是说**公钥无法反推导出私钥，即使攻击者窃听到传输的公钥，也无法正确解出数据**，所以安全性较高。

# 操作系统知识总结

## 进程和线程

### 进程和线程的基本概念

**进程**是对运行时程序的封装，是**系统进行资源调度和分配的基本单位**，实现了操作系统的并发；

**线程**是进程的子任务，是**CPU调度和分派的基本单位**，用于保证程序的实时性，实现进程内部的并发；**线程是操作系统可识别的最小执行和调度单位**。每个线程都独自占用一个虚拟处理器：**独自的寄存器组，指令计数器和处理器状态**。每个线程完成不同的任务，但是**共享同一地址空间**（也就是同样的动态内存，映射文件，目标代码等等），打开的文件队列和其他内核资源。

> 由于共享了除栈以外的所有内存地址段，线程不可以有自己的“静态”或“全局”变量，为了弥补这一缺憾，操作系统通常会提供一种称为 TLS（Thread Local Storage）的机制。通过该机制可以实现类似的功能。TLS 通常是线程控制块（TCB）中的某个指针所指向的一个指针数组，数组中的每个元素称为一个槽（Slot），每个槽中的指针由使用者定义，可以指向任意位置（但通常是指向堆存储中的某个偏移）。

### 进程和线程的区别

1. 一个线程只能属于一个进程，而一个进程可以有多个线程，但至少有一个线程。线程依赖于进程而存在。

2. 进程在执行过程中拥有独立的内存单元，而多个线程共享进程的内存。（资源分配给进程，同一进程的所有线程共享该进程的所有资源。同一进程中的多个线程共享代码段（代码和常量），数据段（全局变量和静态变量），扩展段（堆存储）。但是每个线程拥有自己的栈段（栈段又叫运行时段，用来存放所有局部变量和临时变量。）

3. 进程是资源分配的最小单位，线程是CPU调度的最小单位；

4. 系统开销： 由于在创建或撤消进程时，系统都要为之分配或回收资源，如内存空间、I/O设备等。因此，操作系统所付出的开销将显著地大于在创建或撤消线程时的开销。类似地，在进行进程切换时，涉及到整个当前进程CPU环境的保存以及新被调度运行的进程的CPU环境的设置。而线程切换只须保存和设置少量寄存器的内容，并不涉及存储器管理方面的操作。可见，进程切换的开销也远大于线程切换的开销。

5. 通信：由于同一进程中的多个线程具有相同的地址空间，致使它们之间的同步和通信的实现，也变得比较容易。进程间通信IPC，线程间可以直接读写进程数据段（如全局变量）来进行通信——需要进程同步和互斥手段的辅助，以保证数据的一致性。在有的系统中，线程的切换、同步和通信都无须操作系统内核的干预。

6. 进程编程调试简单可靠性高，但是创建销毁开销大；线程正相反，开销小，切换速度快，但是编程调试相对复杂。

7. 进程间不会相互影响 ；线程一个线程挂掉将导致整个进程挂掉。

8. 进程适应于多核、多机分布；线程适用于多核。

### 进程间通信的方式

进程间通信主要包括**管道、系统IPC（包括消息队列、信号量、信号、共享内存等）、以及套接字socket**。

1. 管道

   管道主要包括无名管道和命名管道：管道可用于具有亲缘关系的父子进程间的通信，有名管道除了具有管道所具有的功能外，它还允许无亲缘关系进程间的通信。

   1.1 普通管道PIPE：

   - 它是半双工的（即数据只能在一个方向上流动），具有固定的读端和写端

   - 它只能用于具有亲缘关系的进程之间的通信（也是父子进程或者兄弟进程之间）

   - 它可以看成是一种特殊的文件，对于它的读写也可以使用普通的 read 、 write 等函数。但是它不是普通的文件，并不属于其他任何文件系统，并且只存在于内存中。

   1.2 命名管道FIFO：

   - FIFO可以在无关的进程之间交换数据

   - FIFO有路径名与之相关联，它以一种特殊设备文件形式存在于文件系统中。

2. 系统IPC：

   2.1 消息队列

   消息队列，是消息的链接表，存放在内核中。一个消息队列由一个标识符（即队列 ID）来标记。（消息队列克服了信号传递信息少，管道只能承载无格式字节流以及缓冲区大小受限等特点）具有写权限的进程可以按照一定的规则向消息队列中添加新信息；对消息队列有读权限的进程则可以从消息队列中读取信息；

   特点：

   - 消息队列是面向记录的，其中的消息具有特定的格式以及特定的优先级。

   - 消息队列独立于发送与接收进程。进程终止时，消息队列及其内容并不会被删除。

   - 消息队列可以实现消息的随机查询，消息不一定要以先进先出的次序读取，也可以按消息的类型读取。

   2.2 信号量 semaphore

   信号量（semaphore）与已经介绍过的 IPC 结构不同，它是一个计数器，可以用来控制多个进程对共享资源的访问。信号量用于实现进程间的互斥与同步，而不是用于存储进程间通信数据。

   特点：

   - 信号量用于进程间同步，若要在进程间传递数据需要结合共享内存。

   - 信号量基于操作系统的 PV 操作，程序对信号量的操作都是原子操作。

   - 每次对信号量的 PV 操作不仅限于对信号量值加 1 或减 1，而且可以加减任意正整数。

   - 支持信号量组。

   2.3 信号 signal

   信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。

   2.4 共享内存（Shared Memory）

   它使得多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中数据得更新。这种方式需要依靠某种同步操作，如互斥锁和信号量等。

   特点：

   - 共享内存是最快的一种IPC，因为进程是直接对内存进行存取。

   - 因为多个进程可以同时操作，所以需要进行同步。

   - 信号量+共享内存通常结合在一起使用，信号量用来同步对共享内存的访问。

3. 套接字 socket

   socket 也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同主机之间的进程通信。

### 线程间通信的方式

1. 临界区

   通过多线程的串行化来访问公共资源或一段代码，速度快，适合控制数据访问。

2. 互斥量 Synchronized/Lock

   采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问。

3. 信号量 Semphare

   为控制具有有限数量的用户资源而设计的，它允许多个线程在同一时刻去访问同一个资源，但一般需要限制同一时刻访问此资源的最大线程数目。

4. 事件（信号），Wait/Notify

   通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作。

### 有了进程为什么还要线程？

进程可以使多个程序能并发执行，以提高资源的利用率和系统的吞吐量；但是其具有一些缺点：

- 进程在**同一时间只能干一件事**
- 进程**在执行的过程中如果阻塞，整个进程就会挂起**，即使进程中有些工作不依赖于等待的资源，仍然不会执行

因此，操作系统引入了比进程粒度更小的线程，作为并发执行的基本单位，从而减少程序在并发执行时所付出的时空开销，提高并发性。和进程相比，线程的优势如下：

- 从**资源**上来讲，线程是一种非常节俭的多任务操作方式。在Linux系统下，启动一个新的进程必须分配给它独立的地址空间，建立众多的数据表来维护它的代码段、堆栈段和数据段，这是一种昂贵的多任务工作方式。
- 从**切换效率**上来讲，运行于一个进程中的多个线程，它们之间使用相同的地址空间，而且线程间彼此切换所需时间也远远小于进程间切换所需要的时间。据统计，一个进程的开销大约是一个线程开销的30倍左右。
- 从**通信机制**上来讲，线程间方便的通信机制。对不同进程来说，它们具有独立的数据空间，要进行数据的传递只能通过进程间通信的方式进行，这种方式不仅费时，而且很不方便。线程则不然，由于同一进程下的线程之间共享数据空间，所以一个线程的数据可以直接为其他线程所用，这不仅快捷，而且方便。

除以上优点外，多线程程序作为一种多任务、并发的工作方式，还有如下优点：

- 使多CPU系统更加有效。**操作系统会保证当线程数不大于CPU数目时，不同的线程运行于不同的CPU上**。
- 改善程序结构。一个既长又复杂的进程可以考虑分为多个线程，成为几个独立或半独立的运行部分，这样的程序才会利于理解和修改。

## Linux虚拟内存空间

### 什么是虚拟内存

为了防止不同进程同一时刻在物理内存中运行而对物理内存的争夺和践踏，采用了虚拟内存。

虚拟内存技术使得不同进程在运行过程中，它所看到的是自己独自占有了当前系统的4G内存。所有进程共享同一物理内存，每个进程只把自己目前需要的虚拟内存空间映射并存储到物理内存上。 事实上，**在每个进程创建加载时，内核只是为进程创建了虚拟内存的布局，具体就是初始化进程控制表中内存相关的链表，实际上并不立即就把虚拟内存对应位置的程序数据和代码（比如.text .data段）拷贝到物理内存中，只是建立好虚拟内存和磁盘文件之间的映射就好（叫做存储器映射），等到运行到对应的程序时，才会通过缺页异常，来拷贝数据**。还有进程运行过程中，要动态分配内存，比如malloc时，也只是分配了虚拟内存，即为这块虚拟内存对应的页表项做相应设置，当进程真正访问到此数据时，才引发缺页异常。

请求分页系统、请求分段系统和请求段页式系统都是针对虚拟内存的，通过请求实现内存与外存的信息置换。

### 虚拟内存的好处

1. 扩大地址空间。

2. 内存保护：每个进程运行在各自的虚拟内存地址空间，互相不能干扰对方。虚存还对特定的内存地址提供写保护，可以防止代码或数据被恶意篡改。

3. 公平内存分配。采用了虚存之后，每个进程都相当于有同样大小的虚存空间。

4. 当进程通信时，可采用虚存共享的方式实现。

5. 当不同的进程使用同样的代码时，比如库文件中的代码，物理内存中可以只存储一份这样的代码，不同的进程只需要把自己的虚拟内存映射过去就可以了，节省内存。

6. 虚拟内存很适合在多道程序设计系统中使用，许多程序的片段同时保存在内存中。当一个程序等待它的一部分读入内存时，可以把CPU交给另一个进程使用。在内存中可以保留多个进程，系统并发度提高。

7. 在程序需要分配连续的内存空间的时候，只需要在虚拟内存空间分配连续空间，而不需要实际物理内存的连续空间，可以利用碎片。

### 虚拟内存的代价

1. 虚存的管理需要建立很多数据结构，这些数据结构要占用额外的内存。

2. 虚拟地址到物理地址的转换，增加了指令的执行时间。

3. 页面的换入换出需要磁盘I/O，这是很耗时的。

4. 如果一页中只有一部分数据，会浪费内存。

### 缺页中断

`malloc()`和`mmap()`等内存分配函数，**在分配时只是建立了进程虚拟地址空间，并没有分配虚拟内存对应的物理内存**。当进程访问这些没有建立映射关系的虚拟内存时，处理器自动触发一个缺页异常。

缺页中断：在请求分页系统中，可以通过查询页表中的状态位来确定所要访问的页面是否存在于内存中。每当所要访问的页面不在内存是，会产生一次缺页中断，此时操作系统会根据页表中的外存地址在外存中找到所缺的一页，将其调入内存。

缺页本身是一种中断，与一般的中断一样，需要经过4个处理步骤：

1. 保护CPU现场

2. 分析中断原因

3. 转入缺页中断处理程序进行处理

4. 恢复CPU现场，继续执行

但是缺页中断是由于所要访问的页面不存在于内存时，由硬件所产生的一种特殊的中断，因此，与一般的中断存在区别：

- 在指令执行期间产生和处理缺页中断信号

- 一条指令在执行期间，可能产生多次缺页中断

- 缺页中断返回是，执行产生中断的一条指令，而一般的中断返回是，执行下一条指令

### 页表寻址

页式内存管理，内存分成固定长度的一个个页片。**操作系统为每一个进程维护了一个从虚拟地址到物理地址的映射关系的数据结构，叫页表**，页表的内容就是该进程的虚拟地址到物理地址的一个映射。页表中的每一项都记录了这个页的基地址。**通过页表，由逻辑地址的高位部分先找到逻辑地址对应的页基地址，再由页基地址偏移一定长度就得到最后的物理地址，偏移的长度由逻辑地址的低位部分决定**。一般情况下，这个过程都可以由硬件完成，所以效率还是比较高的。页式内存管理的优点就是比较灵活，内存管理以较小的页为单位，方便内存换入换出和扩充地址空间。

### 缺页置换

当访问一个内存中不存在的页，并且内存已满，则需要从内存中调出一个页或将数据送至磁盘对换区，替换一个页，这种现象叫做缺页置换。当前操作系统最常采用的缺页置换算法如下：

先进先出（FIFO）算法：**置换最先调入内存的页面，即置换在内存中驻留时间最久的页面**。按照进入内存的先后次序排列成队列，从队尾进入，从队首删除。

最近最少使用（LRU）算法：**置换最近一段时间以来最长时间未访问过的页面**。根据程序局部性原理，刚被访问的页面，可能马上又要被访问；而较长时间内没有被访问的页面，可能最近不会被访问。

当前最常采用的就是LRU算法。

## 并发和并行

### 并发

指宏观上看起来两个程序在同时运行，比如说在单核cpu上的多任务。但是从微观上看两个程序的指令是交织着运行的，你的指令之间穿插着我的指令，我的指令之间穿插着你的，在单个周期内只运行了一个指令。这种并发并不能提高计算机的性能，只能提高效率。

### 并行

指严格物理意义上的同时运行，比如多核cpu，两个程序分别运行在两个核上，两者之间互不影响，单个周期内每个程序都运行了自己的指令，也就是运行了两条指令。这样说来并行的确提高了计算机的效率。所以现在的cpu都是往多核方面发展。

## 死锁

### 死锁发生的条件

死锁是指两个或两个以上进程在执行过程中，因争夺资源而造成的相互等待的现象。死锁发生的四个必要条件如下：

- 互斥条件：**进程对所分配到的资源不允许其他进程访问**，若其他进程访问该资源，只能等待，直至占有该资源的进程使用完成后释放该资源。
- 请求和保持条件：**进程获得一定的资源后，又对其他资源发出请求，但是该资源可能被其他进程占有，此时请求阻塞，但该进程不会释放自己已经占有的资源**。
- 不可剥夺条件：进程已获得的资源，在未完成使用之前，不可被剥夺，只能在使用后自己释放。
- 环路等待条件：**进程发生死锁后，必然存在一个进程-资源之间的环形链**。

### 解决死锁的方法

解决死锁的方法即破坏上述四个条件之一，主要方法如下：

- **资源一次性分配**，从而剥夺请求和保持条件。
- 可剥夺资源：即**当进程新的资源未得到满足时，释放已占有的资源**，从而破坏不可剥夺的条件。
- 资源有序分配法：**系统给每类资源赋予一个序号，每个进程按编号递增的请求资源，释放则相反**，从而破坏环路等待的条件。

## 用户态到内核态的转化原理

用户态切换到内核态的 3 种方式：

1. **系统调用**

   这是用户进程主动要求切换到内核态的一种方式，用户进程通过系统调用申请操作系统提供的服务程序完成工作。而系统调用的机制其核心还是使用了操作系统为用户特别开放的一个中断来实现，例如 Linux 的 ine 80h 中断。

2. **异常**

   当 CPU 在执行运行在用户态的程序时，发现了某些事件不可知的异常，这是会触发由当前运行进程切换到处理此。异常的内核相关程序中，也就到了内核态，比如缺页异常。

3. **外围设备的中断**

   当外围设备完成用户请求的操作之后，会向 CPU 发出相应的中断信号，这时 CPU 会暂停执行下一条将要执行的指令，转而去执行中断信号的处理程序，如果先执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了有用户态到内核态的切换。比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。

切换操作

从出发方式看，可以在认为存在前述3种不同的类型，但是从最终实际完成由用户态到内核态的切换操作上来说，涉及的关键步骤是完全一样的，没有任何区别，都相当于执行了一个中断响应的过程，因为**系统调用实际上最终是中断机制实现的**，而异常和中断处理机制基本上是一样的，用户态切换到内核态的步骤主要包括：

1. 从当前进程的描述符中提取其内核栈的 ss0 及 esp0 信息。

2. 使用 ss0 和 esp0 指向的内核栈将当前进程的 cs ，eip ，eflags ，ss ，esp 信息保存起来，这个过程也完成了由用户栈找到内核栈的切换过程，同时保存了被暂停执行的程序的下一条指令。

3. 将先前由中断向量检索得到的中断处理程序的 cs，eip 信息装入相应的寄存器，开始执行中断处理程序，这时就转到了内核态的程序执行了。

## 线程池

线程池是一种多线程处理形式，处理过程中将任务添加到队列，然后在创建线程后自动启动这些任务。线程池线程都是后台线程。每个线程都使用默认的堆栈大小，以默认的优先级运行，并处于多线程单元中。如果某个线程在托管代码中空闲（如正在等待某个事件），则线程池将插入另一个辅助线程来使所有处理器保持繁忙。如果所有线程池线程都始终保持繁忙，但队列中包含要挂起的工作，则线程池将在一段时间后创建另一个辅助线程但线程的数目永远不会超过最大值。超过最大值的线程可以排队，但他们要等到其它线程完成后才启动。

任务调度以执行线程的常见方法是使用同步队列，称作任务队列。池中的线程等待队列中的任务，并把执行完的任务放入完成队列中。

线程池模式一般分为两种：生产者消费者模式、领导者追随者模式。

- 生产者消费者模式：分为同步层、队列层、异步层。同步层的主线程处理工作任务并存入工作队列，工作线程从工作队列取出任务进行处理，如果工作队列为空，则取不到任务的工作线程进入挂起状态。由于线程间有数据通信，因此不适于大数据量交换的场合。
- 领导者追随者模式：分为领导者、追随者、工作者。在任何时刻线程池只有一个领导者线程。事件到达时，领导者线程负责消息分离，并从追随者线程中选出一个来当继任的领导者，然后将自身设置为工作者状态去处置该事件。处理完毕后工作者线程将自身的状态置为追随者。这一模式实现复杂，但避免了线程间交换任务数据。

线程池的组成部分：

- 线程池管理器：用于创建并管理线程池。
- 工作线程：线程池中的线程。
- 任务接口：每个任务必须实现的接口，以供工作线程调度任务的执行。
- 任务队列：用于存放没有处理的任务，提供一种缓冲机制。

